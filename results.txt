Loss: 1.521462317301097 at step: 0 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5214151530074402 at step: 1 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5213679681765446 at step: 2 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5213207628342458 at step: 3 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5212735370064672 at step: 4 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.521226290719224 at step: 5 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5211790239986203 at step: 6 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5211317368708497 at step: 7 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5210844293621955 at step: 8 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5210371014990307 at step: 9 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5209897533078198 at step: 10 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5209423848151138 at step: 11 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5208949960475544 at step: 12 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5208475870318758 at step: 13 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5208001577948984 at step: 14 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5207527083635333 at step: 15 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.520705238764782 at step: 16 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5206577490257362 at step: 17 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5206102391735759 at step: 18 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5205627092355702 at step: 19 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5205151592390815 at step: 20 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5204675892115582 at step: 21 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5204199991805385 at step: 22 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5203723891736547 at step: 23 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5203247592186224 at step: 24 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5202771093432532 at step: 25 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5202294395754432 at step: 26 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5201817499431813 at step: 27 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5201340404745447 at step: 28 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5200863111976994 at step: 29 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5200385621409045 at step: 30 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5199907933325059 at step: 31 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5199430048009392 at step: 32 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5198951965747303 at step: 33 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5198473686824967 at step: 34 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5197995211529391 at step: 35 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.519751654014855 at step: 36 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5197037672971276 at step: 37 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5196558610287318 at step: 38 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5196079352387286 at step: 39 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5195599899562724 at step: 40 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5195120252106051 at step: 41 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5194640410310574 at step: 42 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5194160374470516 at step: 43 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5193680144880966 at step: 44 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5193199721837929 at step: 45 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5192719105638315 at step: 46 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.519223829657989 at step: 47 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.519175729496133 at step: 48 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5191276101082214 at step: 49 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5190794715243017 at step: 50 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.519031313774509 at step: 51 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5189831368890678 at step: 52 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.518934940898292 at step: 53 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5188867258325862 at step: 54 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5188384917224418 at step: 55 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5187902385984402 at step: 56 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.518741966491253 at step: 57 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5186936754316394 at step: 58 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5186453654504475 at step: 59 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5185970365786154 at step: 60 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5185486888471693 at step: 61 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.518500322287225 at step: 62 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.518451936929987 at step: 63 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5184035328067473 at step: 64 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5183551099488883 at step: 65 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.518306668387881 at step: 66 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5182582081552844 at step: 67 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5182097292827468 at step: 68 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5181612318020035 at step: 69 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5181127157448813 at step: 70 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5180641811432931 at step: 71 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5180156280292398 at step: 72 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.517967056434814 at step: 73 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5179184663921936 at step: 74 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.517869857933645 at step: 75 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5178212310915253 at step: 76 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5177725858982773 at step: 77 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5177239223864327 at step: 78 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5176752405886123 at step: 79 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5176265405375247 at step: 80 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5175778222659648 at step: 81 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5175290858068171 at step: 82 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5174803311930538 at step: 83 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5174315584577358 at step: 84 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5173827676340093 at step: 85 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5173339587551105 at step: 86 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5172851318543639 at step: 87 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.517236286965177 at step: 88 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5171874241210521 at step: 89 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5171385433555715 at step: 90 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.517089644702411 at step: 91 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5170407281953306 at step: 92 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5169917938681776 at step: 93 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5169428417548887 at step: 94 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.516893871889485 at step: 95 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5168448843060776 at step: 96 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5167958790388623 at step: 97 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5167468561221225 at step: 98 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.516697815590228 at step: 99 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5166487574776384 at step: 100 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.516599681818897 at step: 101 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5165505886486343 at step: 102 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5165014780015673 at step: 103 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.516452349912501 at step: 104 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5164032044163267 at step: 105 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5163540415480194 at step: 106 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5163048613426449 at step: 107 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.51625566383535 at step: 108 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5162064490613723 at step: 109 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.516157217056034 at step: 110 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5161079678547416 at step: 111 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5160587014929896 at step: 112 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5160094180063568 at step: 113 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.51596011743051 at step: 114 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5159107998011996 at step: 115 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5158614651542628 at step: 116 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.515812113525622 at step: 117 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5157627449512836 at step: 118 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5157133594673415 at step: 119 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5156639571099733 at step: 120 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5156145379154449 at step: 121 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5155651019201013 at step: 122 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5155156491603776 at step: 123 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5154661796727942 at step: 124 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.515416693493951 at step: 125 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5153671906605377 at step: 126 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5153176712093257 at step: 127 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5152681351771746 at step: 128 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5152185826010238 at step: 129 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5151690135178988 at step: 130 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5151194279649112 at step: 131 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.515069825979253 at step: 132 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5150202075982049 at step: 133 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5149705728591278 at step: 134 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5149209217994677 at step: 135 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5148712544567535 at step: 136 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5148215708686 at step: 137 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5147718710727032 at step: 138 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5147221551068433 at step: 139 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.514672423008884 at step: 140 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5146226748167713 at step: 141 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5145729105685364 at step: 142 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5145231303022906 at step: 143 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5144733340562306 at step: 144 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5144235218686344 at step: 145 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5143736937778625 at step: 146 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.51432384982236 at step: 147 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5142739900406514 at step: 148 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5142241144713453 at step: 149 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5141742231531325 at step: 150 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5141243161247855 at step: 151 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5140743934251586 at step: 152 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5140244550931876 at step: 153 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5139745011678931 at step: 154 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5139245316883705 at step: 155 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5138745466938048 at step: 156 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5138245462234559 at step: 157 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5137745303166699 at step: 158 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5137244990128684 at step: 159 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5136744523515597 at step: 160 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5136243903723292 at step: 161 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5135743131148467 at step: 162 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5135242206188564 at step: 163 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5134741129241878 at step: 164 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5134239900707516 at step: 165 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5133738520985354 at step: 166 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5133236990476078 at step: 167 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5132735309581178 at step: 168 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5132233478702959 at step: 169 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.513173149824449 at step: 170 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5131229368609656 at step: 171 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5130727090203129 at step: 172 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.513022466343037 at step: 173 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5129722088697661 at step: 174 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5129219366412021 at step: 175 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5128716496981303 at step: 176 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5128213480814126 at step: 177 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5127710318319907 at step: 178 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5127207009908832 at step: 179 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.512670355599188 at step: 180 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5126199956980801 at step: 181 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.512569621328815 at step: 182 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5125192325327235 at step: 183 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.512468829351215 at step: 184 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5124184118257755 at step: 185 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5123679799979715 at step: 186 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5123175339094423 at step: 187 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5122670736019086 at step: 188 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5122165991171643 at step: 189 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5121661104970838 at step: 190 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5121156077836135 at step: 191 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5120650910187816 at step: 192 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5120145602446888 at step: 193 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.511964015503513 at step: 194 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5119134568375094 at step: 195 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.511862884289006 at step: 196 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5118122979004114 at step: 197 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5117616977142052 at step: 198 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5117110837729437 at step: 199 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5116604561192604 at step: 200 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5116098147958597 at step: 201 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5115591598455251 at step: 202 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5115084913111139 at step: 203 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5114578092355564 at step: 204 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5114071136618568 at step: 205 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5113564046330976 at step: 206 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5113056821924313 at step: 207 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5112549463830853 at step: 208 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5112041972483614 at step: 209 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5111534348316358 at step: 210 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5111026591763557 at step: 211 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.511051870326042 at step: 212 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.511001068324291 at step: 213 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5109502532147694 at step: 214 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.510899425041219 at step: 215 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5108485838474512 at step: 216 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5107977296773516 at step: 217 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.510746862574877 at step: 218 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5106959825840574 at step: 219 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.510645089748993 at step: 220 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5105941841138575 at step: 221 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5105432657228954 at step: 222 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5104923346204209 at step: 223 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5104413908508205 at step: 224 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5103904344585535 at step: 225 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5103394654881461 at step: 226 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5102884839841975 at step: 227 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5102374899913775 at step: 228 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5101864835544245 at step: 229 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.510135464718147 at step: 230 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5100844335274257 at step: 231 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.510033390027207 at step: 232 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5099823342625105 at step: 233 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.509931266278422 at step: 234 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5098801861200988 at step: 235 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.509829093832764 at step: 236 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.509777989461713 at step: 237 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5097268730523072 at step: 238 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5096757446499762 at step: 239 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.509624604300218 at step: 240 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5095734520485997 at step: 241 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.509522287940754 at step: 242 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.509471112022383 at step: 243 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5094199243392536 at step: 244 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5093687249372039 at step: 245 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5093175138621322 at step: 246 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5092662911600112 at step: 247 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5092150568768732 at step: 248 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5091638110588208 at step: 249 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5091125537520231 at step: 250 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5090612850027103 at step: 251 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5090100048571837 at step: 252 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5089587133618056 at step: 253 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.508907410563008 at step: 254 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.508856096507284 at step: 255 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.508804771241192 at step: 256 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5087534348113574 at step: 257 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5087020872644683 at step: 258 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5086507286472757 at step: 259 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5085993590065976 at step: 260 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5085479783893105 at step: 261 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5084965868423614 at step: 262 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5084451844127553 at step: 263 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5083937711475626 at step: 264 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.508342347093914 at step: 265 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5082909122990078 at step: 266 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5082394668100982 at step: 267 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5081880106745067 at step: 268 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5081365439396155 at step: 269 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5080850666528662 at step: 270 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5080335788617654 at step: 271 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5079820806138797 at step: 272 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5079305719568332 at step: 273 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5078790529383173 at step: 274 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5078275236060794 at step: 275 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5077759840079283 at step: 276 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5077244341917333 at step: 277 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5076728742054248 at step: 278 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5076213040969908 at step: 279 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5075697239144792 at step: 280 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.507518133705997 at step: 281 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5074665335197137 at step: 282 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5074149234038514 at step: 283 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.507363303406696 at step: 284 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.507311673576589 at step: 285 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.507260033961931 at step: 286 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5072083846111801 at step: 287 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5071567255728522 at step: 288 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5071050568955198 at step: 289 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5070533786278129 at step: 290 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.507001690818419 at step: 291 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5069499935160828 at step: 292 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5068982867696037 at step: 293 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5068465706278376 at step: 294 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5067948451396973 at step: 295 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5067431103541515 at step: 296 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5066913663202224 at step: 297 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5066396130869888 at step: 298 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.506587850703585 at step: 299 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5065360792191986 at step: 300 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.506484298683073 at step: 301 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5064325091445046 at step: 302 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5063807106528442 at step: 303 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5063289032574974 at step: 304 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5062770870079218 at step: 305 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5062252619536283 at step: 306 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.506173428144182 at step: 307 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5061215856292 at step: 308 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5060697344583507 at step: 309 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5060178746813577 at step: 310 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5059660063479936 at step: 311 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5059141295080845 at step: 312 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5058622442115057 at step: 313 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.505810350508188 at step: 314 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.505758448448108 at step: 315 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5057065380812957 at step: 316 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5056546194578329 at step: 317 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5056026926278503 at step: 318 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5055507576415248 at step: 319 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5054988145490908 at step: 320 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.505446863400825 at step: 321 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5053949042470562 at step: 322 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.505342937138162 at step: 323 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5052909621245687 at step: 324 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5052389792567507 at step: 325 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.50518698858523 at step: 326 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5051349901605775 at step: 327 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5050829840334106 at step: 328 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5050309702543951 at step: 329 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.504978948874242 at step: 330 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.504926919943711 at step: 331 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.504874883513608 at step: 332 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5048228396347851 at step: 333 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5047707883581376 at step: 334 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5047187297346114 at step: 335 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5046666638151946 at step: 336 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5046145906509205 at step: 337 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5045625102928686 at step: 338 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5045104227921615 at step: 339 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5044583281999682 at step: 340 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5044062265674998 at step: 341 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5043541179460127 at step: 342 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5043020023868046 at step: 343 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5042498799412198 at step: 344 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5041977506606423 at step: 345 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5041456145965006 at step: 346 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5040934718002656 at step: 347 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5040413223234501 at step: 348 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5039891662176086 at step: 349 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5039370035343353 at step: 350 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5038848343252706 at step: 351 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5038326586420916 at step: 352 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.503780476536518 at step: 353 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5037282880603082 at step: 354 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5036760932652635 at step: 355 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5036238922032235 at step: 356 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5035716849260672 at step: 357 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.503519471485713 at step: 358 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.50346725193412 at step: 359 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5034150263232835 at step: 360 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5033627947052406 at step: 361 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5033105571320617 at step: 362 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.503258313655861 at step: 363 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.503206064328785 at step: 364 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5031538092030219 at step: 365 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5031015483307937 at step: 366 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5030492817643608 at step: 367 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5029970095560206 at step: 368 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5029447317581042 at step: 369 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5028924484229822 at step: 370 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5028401596030574 at step: 371 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5027878653507702 at step: 372 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.502735565718596 at step: 373 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5026832607590435 at step: 374 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5026309505246558 at step: 375 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5025786350680117 at step: 376 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5025263144417236 at step: 377 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5024739886984375 at step: 378 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5024216578908312 at step: 379 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.502369322071617 at step: 380 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5023169812935382 at step: 381 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5022646356093738 at step: 382 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5022122850719326 at step: 383 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5021599297340544 at step: 384 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5021075696486121 at step: 385 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5020552048685092 at step: 386 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5020028354466803 at step: 387 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5019504614360917 at step: 388 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5018980828897373 at step: 389 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.501845699860644 at step: 390 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5017933124018668 at step: 391 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5017409205664896 at step: 392 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5016885244076268 at step: 393 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.501636123978422 at step: 394 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5015837193320454 at step: 395 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5015313105216967 at step: 396 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5014788976006037 at step: 397 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.501426480622022 at step: 398 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5013740596392335 at step: 399 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5013216347055462 at step: 400 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5012692058742991 at step: 401 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5012167731988524 at step: 402 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5011643367325955 at step: 403 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5011118965289447 at step: 404 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.501059452641337 at step: 405 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.501007005123241 at step: 406 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5009545540281437 at step: 407 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5009020994095619 at step: 408 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5008496413210344 at step: 409 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5007971798161237 at step: 410 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5007447149484168 at step: 411 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5006922467715236 at step: 412 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5006397753390786 at step: 413 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5005873007047361 at step: 414 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5005348229221753 at step: 415 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.500482342045097 at step: 416 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5004298581272217 at step: 417 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5003773712222954 at step: 418 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5003248813840833 at step: 419 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5002723886663698 at step: 420 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5002198931229633 at step: 421 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5001673948076895 at step: 422 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5001148937743947 at step: 423 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.500062390076948 at step: 424 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.5000098837692333 at step: 425 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.499957374905155 at step: 426 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4999048635386387 at step: 427 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4998523497236254 at step: 428 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4997998335140754 at step: 429 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4997473149639675 at step: 430 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4996947941272962 at step: 431 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4996422710580752 at step: 432 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4995897458103329 at step: 433 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4995372184381168 at step: 434 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4994846889954878 at step: 435 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4994321575365257 at step: 436 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4993796241153219 at step: 437 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4993270887859889 at step: 438 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4992745516026484 at step: 439 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.49922201261944 at step: 440 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4991694718905169 at step: 441 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4991169294700457 at step: 442 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.499064385412209 at step: 443 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4990118397711996 at step: 444 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4989592926012247 at step: 445 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4989067439565058 at step: 446 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4988541938912743 at step: 447 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.498801642459775 at step: 448 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4987490897162656 at step: 449 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.498696535715013 at step: 450 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4986439805102978 at step: 451 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.498591424156409 at step: 452 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.498538866707647 at step: 453 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4984863082183242 at step: 454 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4984337487427604 at step: 455 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4983811883352869 at step: 456 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4983286270502425 at step: 457 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.498276064941977 at step: 458 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4982235020648458 at step: 459 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4981709384732171 at step: 460 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4981183742214639 at step: 461 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.498065809363967 at step: 462 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.498013243955115 at step: 463 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4979606780493047 at step: 464 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4979081117009383 at step: 465 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.497855544964424 at step: 466 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.497802977894178 at step: 467 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4977504105446222 at step: 468 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4976978429701802 at step: 469 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.497645275225286 at step: 470 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4975927073643733 at step: 471 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4975401394418852 at step: 472 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.497487571512267 at step: 473 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4974350036299666 at step: 474 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4973824358494356 at step: 475 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4973298682251304 at step: 476 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4972773008115108 at step: 477 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.497224733663037 at step: 478 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4971721668341709 at step: 479 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4971196003793796 at step: 480 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.497067034353131 at step: 481 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4970144688098912 at step: 482 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4969619038041309 at step: 483 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4969093393903188 at step: 484 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4968567756229274 at step: 485 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4968042125564252 at step: 486 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4967516502452822 at step: 487 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4966990887439688 at step: 488 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4966465281069534 at step: 489 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.496593968388702 at step: 490 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4965414096436827 at step: 491 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4964888519263575 at step: 492 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4964362952911876 at step: 493 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4963837397926325 at step: 494 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4963311854851484 at step: 495 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4962786324231891 at step: 496 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4962260806612033 at step: 497 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4961735302536379 at step: 498 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4961209812549323 at step: 499 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.496068433719526 at step: 500 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4960158877018492 at step: 501 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4959633432563308 at step: 502 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4959108004373922 at step: 503 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4958582592994472 at step: 504 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4958057198969104 at step: 505 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4957531822841819 at step: 506 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.49570064651566 at step: 507 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.495648112645735 at step: 508 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.495595580728788 at step: 509 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4955430508191958 at step: 510 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4954905229713251 at step: 511 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4954379972395344 at step: 512 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4953854736781726 at step: 513 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4953329523415833 at step: 514 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.495280433284097 at step: 515 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4952279165600373 at step: 516 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.495175402223715 at step: 517 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.495122890329434 at step: 518 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4950703809314851 at step: 519 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4950178740841493 at step: 520 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4949653698416976 at step: 521 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4949128682583879 at step: 522 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.494860369388467 at step: 523 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4948078732861687 at step: 524 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4947553800057156 at step: 525 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4947028896013166 at step: 526 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4946504021271692 at step: 527 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4945979176374533 at step: 528 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4945454361863422 at step: 529 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4944929578279897 at step: 530 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4944404826165356 at step: 531 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4943880106061063 at step: 532 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.494335541850814 at step: 533 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4942830764047554 at step: 534 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4942306143220105 at step: 535 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.494178155656642 at step: 536 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4941257004627002 at step: 537 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4940732487942163 at step: 538 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4940208007052063 at step: 539 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4939683562496675 at step: 540 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4939159154815798 at step: 541 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4938634784549052 at step: 542 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4938110452235902 at step: 543 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4937586158415601 at step: 544 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4937061903627211 at step: 545 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4936537688409621 at step: 546 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4936013513301536 at step: 547 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4935489378841438 at step: 548 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4934965285567607 at step: 549 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4934441234018159 at step: 550 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4933917224730968 at step: 551 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4933393258243703 at step: 552 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4932869335093841 at step: 553 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4932345455818612 at step: 554 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4931821620955061 at step: 555 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4931297831039996 at step: 556 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4930774086609986 at step: 557 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4930250388201403 at step: 558 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4929726736350373 at step: 559 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4929203131592779 at step: 560 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4928679574464279 at step: 561 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4928156065500278 at step: 562 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.492763260523596 at step: 563 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4927109194206252 at step: 564 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4926585832945816 at step: 565 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4926062521989087 at step: 566 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4925539261870227 at step: 567 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4925016053123155 at step: 568 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.492449289628151 at step: 569 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4923969791878677 at step: 570 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4923446740447774 at step: 571 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4922923742521645 at step: 572 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4922400798632864 at step: 573 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4921877909313728 at step: 574 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4921355075096245 at step: 575 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4920832296512148 at step: 576 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.492030957409289 at step: 577 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4919786908369626 at step: 578 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4919264299873223 at step: 579 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.491874174913424 at step: 580 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.491821925668297 at step: 581 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4917696823049376 at step: 582 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4917174448763117 at step: 583 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.491665213435356 at step: 584 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4916129880349767 at step: 585 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4915607687280459 at step: 586 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4915085555674075 at step: 587 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4914563486058705 at step: 588 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4914041478962135 at step: 589 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4913519534911823 at step: 590 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.49129976544349 at step: 591 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4912475838058161 at step: 592 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.491195408630808 at step: 593 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4911432399710756 at step: 594 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4910910778792004 at step: 595 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.491038922407726 at step: 596 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4909867736091638 at step: 597 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4909346315359862 at step: 598 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4908824962406357 at step: 599 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4908303677755157 at step: 600 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4907782461929941 at step: 601 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4907261315454057 at step: 602 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4906740238850462 at step: 603 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4906219232641758 at step: 604 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4905698297350163 at step: 605 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4905177433497538 at step: 606 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4904656641605392 at step: 607 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4904135922194786 at step: 608 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4903615275786481 at step: 609 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4903094702900812 at step: 610 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4902574204057726 at step: 611 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4902053779776794 at step: 612 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4901533430577192 at step: 613 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.490101315697771 at step: 614 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4900492959496707 at step: 615 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4899972838652182 at step: 616 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4899452794961703 at step: 617 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.489893282894245 at step: 618 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.489841294111118 at step: 619 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4897893131984248 at step: 620 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4897373402077596 at step: 621 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4896853751906733 at step: 622 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4896334181986755 at step: 623 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4895814692832348 at step: 624 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4895295284957761 at step: 625 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.48947759588768 at step: 626 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4894256715102876 at step: 627 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4893737554148925 at step: 628 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4893218476527477 at step: 629 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4892699482750604 at step: 630 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.489218057332994 at step: 631 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4891661748776677 at step: 632 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.489114300960156 at step: 633 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4890624356314892 at step: 634 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4890105789426478 at step: 635 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.488958730944573 at step: 636 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.488906891688156 at step: 637 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4888550612242428 at step: 638 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4888032396036321 at step: 639 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4887514268770778 at step: 640 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.488699623095286 at step: 641 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.488647828308915 at step: 642 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4885960425685767 at step: 643 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4885442659248322 at step: 644 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.488492498428198 at step: 645 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.488440740129142 at step: 646 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4883889910780819 at step: 647 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4883372513253863 at step: 648 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4882855209213761 at step: 649 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4882337999163224 at step: 650 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4881820883604469 at step: 651 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4881303863039208 at step: 652 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.488078693796864 at step: 653 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.488027010889349 at step: 654 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.487975337631394 at step: 655 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.487923674072969 at step: 656 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.487872020263993 at step: 657 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.487820376254331 at step: 658 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4877687420937975 at step: 659 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.487717117832156 at step: 660 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4876655035191153 at step: 661 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4876138992043357 at step: 662 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4875623049374198 at step: 663 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4875107207679215 at step: 664 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4874591467453393 at step: 665 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4874075829191171 at step: 666 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.487356029338647 at step: 667 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4873044860532676 at step: 668 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.48725295311226 at step: 669 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4872014305648544 at step: 670 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4871499184602244 at step: 671 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4870984168474877 at step: 672 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4870469257757088 at step: 673 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.486995445293895 at step: 674 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4869439754509994 at step: 675 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.486892516295917 at step: 676 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4868410678774882 at step: 677 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4867896302444965 at step: 678 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4867382034456689 at step: 679 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.486686787529673 at step: 680 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.486635382545123 at step: 681 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4865839885405738 at step: 682 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4865326055645203 at step: 683 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.486481233665404 at step: 684 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4864298728916048 at step: 685 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4863785232914455 at step: 686 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4863271849131898 at step: 687 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4862758578050408 at step: 688 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4862245420151479 at step: 689 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.486173237591594 at step: 690 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.486121944582407 at step: 691 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4860706630355534 at step: 692 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4860193929989405 at step: 693 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4859681345204132 at step: 694 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4859168876477586 at step: 695 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4858656524287022 at step: 696 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4858144289109056 at step: 697 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4857632171419735 at step: 698 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4857120171694458 at step: 699 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4856608290408027 at step: 700 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4856096528034608 at step: 701 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4855584885047777 at step: 702 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.485507336192043 at step: 703 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4854561959124895 at step: 704 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4854050677132844 at step: 705 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4853539516415308 at step: 706 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4853028477442705 at step: 707 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4852517560684833 at step: 708 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4852006766610788 at step: 709 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4851496095689096 at step: 710 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4850985548387605 at step: 711 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4850475125173541 at step: 712 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4849964826513458 at step: 713 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4849454652873273 at step: 714 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4848944604718284 at step: 715 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4848434682513063 at step: 716 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.48479248867216 at step: 717 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4847415217807198 at step: 718 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4846905676232494 at step: 719 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.484639626245946 at step: 720 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4845886976949447 at step: 721 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.484537782016309 at step: 722 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.484486879256039 at step: 723 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4844359894600658 at step: 724 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.484385112674254 at step: 725 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4843342489444022 at step: 726 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4842833983162382 at step: 727 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4842325608354252 at step: 728 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4841817365475583 at step: 729 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4841309254981616 at step: 730 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4840801277326925 at step: 731 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.484029343296541 at step: 732 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4839785722350274 at step: 733 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4839278145934014 at step: 734 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4838770704168462 at step: 735 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4838263397504745 at step: 736 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4837756226393288 at step: 737 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4837249191283814 at step: 738 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4836742292625371 at step: 739 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4836235530866273 at step: 740 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4835728906454166 at step: 741 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4835222419835958 at step: 742 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.483471607145787 at step: 743 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.48342098617654 at step: 744 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4833703791203345 at step: 745 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4833197860215785 at step: 746 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4832692069246076 at step: 747 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4832186418736888 at step: 748 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4831680909130125 at step: 749 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4831175540867014 at step: 750 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.483067031438803 at step: 751 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.483016523013295 at step: 752 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4829660288540778 at step: 753 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4829155490049852 at step: 754 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4828650835097743 at step: 755 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.482814632412129 at step: 756 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4827641957556603 at step: 757 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4827137735839064 at step: 758 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4826633659403314 at step: 759 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4826129728683257 at step: 760 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4825625944112049 at step: 761 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4825122306122114 at step: 762 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4824618815145114 at step: 763 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4824115471611994 at step: 764 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4823612275952915 at step: 765 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.482310922859733 at step: 766 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4822606329973913 at step: 767 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4822103580510582 at step: 768 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.482160098063452 at step: 769 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.482109853077214 at step: 770 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4820596231349126 at step: 771 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4820094082790338 at step: 772 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4819592085519946 at step: 773 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.481909023996132 at step: 774 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.481858854653706 at step: 775 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4818087005669036 at step: 776 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4817585617778315 at step: 777 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4817084383285204 at step: 778 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4816583302609245 at step: 779 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4816082376169215 at step: 780 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.48155816043831 at step: 781 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4815080987668112 at step: 782 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4814580526440708 at step: 783 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.481408022111653 at step: 784 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4813580072110475 at step: 785 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.481308007983665 at step: 786 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4812580244708349 at step: 787 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4812080567138124 at step: 788 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.481158104753771 at step: 789 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4811081686318084 at step: 790 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4810582483889396 at step: 791 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4810083440661035 at step: 792 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4809584557041584 at step: 793 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4809085833438833 at step: 794 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4808587270259799 at step: 795 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4808088867910656 at step: 796 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4807590626796827 at step: 797 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4807092547322906 at step: 798 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4806594629892715 at step: 799 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.480609687490923 at step: 800 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4805599282774669 at step: 801 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.480510185389042 at step: 802 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4804604588657055 at step: 803 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4804107487474376 at step: 804 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.480361055074134 at step: 805 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4803113778856105 at step: 806 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.480261717221603 at step: 807 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.480212073121764 at step: 808 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4801624456256657 at step: 809 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4801128347727996 at step: 810 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4800632406025727 at step: 811 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4800136631543133 at step: 812 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4799641024672652 at step: 813 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.479914558580592 at step: 814 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4798650315333752 at step: 815 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4798155213646111 at step: 816 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4797660281132177 at step: 817 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.479716551818028 at step: 818 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4796670925177906 at step: 819 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4796176502511753 at step: 820 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.479568225056767 at step: 821 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4795188169730655 at step: 822 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4794694260384913 at step: 823 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.479420052291379 at step: 824 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4793706957699797 at step: 825 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.479321356512462 at step: 826 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4792720345569126 at step: 827 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4792227299413292 at step: 828 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.47917344270363 at step: 829 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4791241728816487 at step: 830 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.479074920513133 at step: 831 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4790256856357482 at step: 832 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.478976468287075 at step: 833 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4789272685046086 at step: 834 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4788780863257605 at step: 835 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4788289217878563 at step: 836 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4787797749281402 at step: 837 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4787306457837672 at step: 838 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.478681534391811 at step: 839 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.478632440789257 at step: 840 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4785833650130085 at step: 841 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4785343070998815 at step: 842 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4784852670866062 at step: 843 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4784362450098303 at step: 844 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4783872409061125 at step: 845 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4783382548119275 at step: 846 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4782892867636641 at step: 847 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4782403367976251 at step: 848 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4781914049500273 at step: 849 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4781424912570018 at step: 850 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.478093595754594 at step: 851 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4780447184787613 at step: 852 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4779958594653753 at step: 853 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4779470187502226 at step: 854 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4778981963690028 at step: 855 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4778493923573284 at step: 856 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4778006067507243 at step: 857 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4777518395846305 at step: 858 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4777030908943996 at step: 859 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.477654360715296 at step: 860 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4776056490824983 at step: 861 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4775569560310988 at step: 862 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4775082815961003 at step: 863 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4774596258124197 at step: 864 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.477410988714887 at step: 865 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4773623703382441 at step: 866 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.477313770717145 at step: 867 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.477265189886158 at step: 868 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4772166278797605 at step: 869 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4771680847323463 at step: 870 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4771195604782164 at step: 871 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4770710551515887 at step: 872 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4770225687865899 at step: 873 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4769741014172608 at step: 874 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4769256530775525 at step: 875 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4768772238013297 at step: 876 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4768288136223655 at step: 877 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4767804225743488 at step: 878 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.476732050690879 at step: 879 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4766836980054638 at step: 880 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4766353645515273 at step: 881 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4765870503624017 at step: 882 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4765387554713314 at step: 883 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4764904799114726 at step: 884 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4764422237158927 at step: 885 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.476393986917569 at step: 886 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.476345769549392 at step: 887 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4762975716441615 at step: 888 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4762493932345897 at step: 889 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4762012343532978 at step: 890 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4761530950328199 at step: 891 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4761049753056001 at step: 892 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4760568752039946 at step: 893 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4760087947602663 at step: 894 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4759607340065943 at step: 895 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4759126929750643 at step: 896 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4758646716976735 at step: 897 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4758166702063304 at step: 898 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4757686885328543 at step: 899 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4757207267089731 at step: 900 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4756727847663265 at step: 901 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4756248627364648 at step: 902 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4755769606508469 at step: 903 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.475529078540844 at step: 904 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.475481216437737 at step: 905 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4754333743727144 at step: 906 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4753855523768777 at step: 907 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4753377504812397 at step: 908 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4752899687167182 at step: 909 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4752422071141462 at step: 910 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4751944657042633 at step: 911 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4751467445177207 at step: 912 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4750990435850786 at step: 913 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4750513629368076 at step: 914 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4750037026032874 at step: 915 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4749560626148095 at step: 916 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4749084430015713 at step: 917 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4748608437936839 at step: 918 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.474813265021166 at step: 919 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4747657067139455 at step: 920 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4747181689018625 at step: 921 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4746706516146637 at step: 922 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.474623154882007 at step: 923 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.474575678733458 at step: 924 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.474528223198496 at step: 925 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.474480788306504 at step: 926 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4744333740867805 at step: 927 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.474385980568528 at step: 928 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4743386077808616 at step: 929 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4742912557528045 at step: 930 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4742439245132912 at step: 931 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4741966140911622 at step: 932 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4741493245151713 at step: 933 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4741020558139775 at step: 934 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4740548080161524 at step: 935 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4740075811501743 at step: 936 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4739603752444335 at step: 937 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4739131903272267 at step: 938 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4738660264267618 at step: 939 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4738188835711552 at step: 940 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.473771761788434 at step: 941 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4737246611065302 at step: 942 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4736775815532892 at step: 943 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.473630523156465 at step: 944 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.47358348594372 at step: 945 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4735364699426228 at step: 946 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4734894751806573 at step: 947 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4734425016852126 at step: 948 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4733955494835866 at step: 949 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4733486186029867 at step: 950 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.473301709070532 at step: 951 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4732548209132463 at step: 952 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4732079541580678 at step: 953 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4731611088318382 at step: 954 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.473114284961312 at step: 955 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.473067482573152 at step: 956 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.473020701693929 at step: 957 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.472973942350125 at step: 958 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4729272045681294 at step: 959 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4728804883742408 at step: 960 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4728337937946665 at step: 961 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4727871208555259 at step: 962 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4727404695828432 at step: 963 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4726938400025547 at step: 964 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4726472321405049 at step: 965 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4726006460224468 at step: 966 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4725540816740441 at step: 967 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4725075391208682 at step: 968 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4724610183884006 at step: 969 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4724145195020308 at step: 970 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4723680424870593 at step: 971 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4723215873686935 at step: 972 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.472275154172052 at step: 973 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4722287429221619 at step: 974 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4721823536439587 at step: 975 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4721359863622896 at step: 976 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4720896411019075 at step: 977 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4720433178874768 at step: 978 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4719970167435712 at step: 979 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4719507376946739 at step: 980 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.471904480765176 at step: 981 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.471858245979379 at step: 982 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4718120333614941 at step: 983 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4717658429356402 at step: 984 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4717196747258485 at step: 985 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4716735287560574 at step: 986 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4716274050501141 at step: 987 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4715813036317773 at step: 988 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4715352245247144 at step: 989 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4714891677525022 at step: 990 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.471443133338627 at step: 991 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.471397121306485 at step: 992 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4713511316793824 at step: 993 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4713051644805326 at step: 994 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4712592197330634 at step: 995 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4712132974600067 at step: 996 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.471167397684308 at step: 997 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.471121520428822 at step: 998 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4710756657163115 at step: 999 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.471029833569451 at step: 1000 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4709840240108243 at step: 1001 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.470938237062923 at step: 1002 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4708924727481534 at step: 1003 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4708467310888267 at step: 1004 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4708010121071675 at step: 1005 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4707553158253084 at step: 1006 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4707096422652925 at step: 1007 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.470663991449074 at step: 1008 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4706183633985166 at step: 1009 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4705727581353933 at step: 1010 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.47052717568139 at step: 1011 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4704816160580996 at step: 1012 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4704360792870266 at step: 1013 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4703905653895881 at step: 1014 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4703450743871058 at step: 1015 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4702996063008196 at step: 1016 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4702541611518734 at step: 1017 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4702087389613248 at step: 1018 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.470163339750142 at step: 1019 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4701179635392005 at step: 1020 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4700726103492916 at step: 1021 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4700272802011127 at step: 1022 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4699819731152763 at step: 1023 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4699366891123018 at step: 1024 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.469891428212621 at step: 1025 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4698461904365776 at step: 1026 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.469800975804424 at step: 1027 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4697557843363263 at step: 1028 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.469710616052359 at step: 1029 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4696654709725103 at step: 1030 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4696203491166768 at step: 1031 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4695752505046689 at step: 1032 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4695301751562075 at step: 1033 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4694851230909232 at step: 1034 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4694400943283603 at step: 1035 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4693950888879725 at step: 1036 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4693501067891277 at step: 1037 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.469305148051101 at step: 1038 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4692602126930854 at step: 1039 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4692153007341804 at step: 1040 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.469170412193397 at step: 1041 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4691255470896616 at step: 1042 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.469080705441811 at step: 1043 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4690358872685927 at step: 1044 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4689910925886673 at step: 1045 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4689463214206078 at step: 1046 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4689015737828974 at step: 1047 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.468856849693935 at step: 1048 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4688121491720287 at step: 1049 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4687674722353978 at step: 1050 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4687228189021786 at step: 1051 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.468678189190415 at step: 1052 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.468633583118068 at step: 1053 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4685890007030065 at step: 1054 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4685444419630156 at step: 1055 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4684999069157911 at step: 1056 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4684553955789421 at step: 1057 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4684109079699925 at step: 1058 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4683664441063746 at step: 1059 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4683220040054374 at step: 1060 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4682775876844434 at step: 1061 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4682331951605647 at step: 1062 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.46818882645089 at step: 1063 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4681444815724198 at step: 1064 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4681001605420685 at step: 1065 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4680558633766623 at step: 1066 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4680115900929427 at step: 1067 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4679673407075642 at step: 1068 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4679231152370953 at step: 1069 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.467878913698018 at step: 1070 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4678347361067279 at step: 1071 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4677905824795343 at step: 1072 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4677464528326607 at step: 1073 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4677023471822452 at step: 1074 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4676582655443386 at step: 1075 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.467614207934909 at step: 1076 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4675701743698333 at step: 1077 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4675261648649087 at step: 1078 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4674821794358432 at step: 1079 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4674382180982601 at step: 1080 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.467394280867698 at step: 1081 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4673503677596105 at step: 1082 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.467306478789363 at step: 1083 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4672626139722404 at step: 1084 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.467218773323438 at step: 1085 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4671749568580688 at step: 1086 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4671311645911602 at step: 1087 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4670873965376567 at step: 1088 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.467043652712415 at step: 1089 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.466999933130208 at step: 1090 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4669562378057253 at step: 1091 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4669125667535705 at step: 1092 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4668689199882643 at step: 1093 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4668252975242428 at step: 1094 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.466781699375856 at step: 1095 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4667381255573733 at step: 1096 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4666945760829768 at step: 1097 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4666510509667672 at step: 1098 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4666075502227587 at step: 1099 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4665640738648853 at step: 1100 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.466520621906994 at step: 1101 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.46647719436285 at step: 1102 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4664337912461343 at step: 1103 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4663904125704457 at step: 1104 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.466347058349298 at step: 1105 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4663037285961236 at step: 1106 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4662604233242706 at step: 1107 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.466217142547004 at step: 1108 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.466173886277508 at step: 1109 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.466130654528881 at step: 1110 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4660874473141405 at step: 1111 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4660442646462215 at step: 1112 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4660011065379759 at step: 1113 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.465957973002173 at step: 1114 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4659148640515012 at step: 1115 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4658717796985647 at step: 1116 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4658287199558873 at step: 1117 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.46578568483591 at step: 1118 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4657426743509907 at step: 1119 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4656996885134093 at step: 1120 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4656567273353591 at step: 1121 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4656137908289557 at step: 1122 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4655708790062314 at step: 1123 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4655279918791382 at step: 1124 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4654851294595437 at step: 1125 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4654422917592405 at step: 1126 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4653994787899314 at step: 1127 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4653566905632478 at step: 1128 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.465313927090732 at step: 1129 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4652711883838516 at step: 1130 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.46522847445399 at step: 1131 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.465185785312451 at step: 1132 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4651431209704584 at step: 1133 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4651004814391553 at step: 1134 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4650578667296046 at step: 1135 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4650152768527884 at step: 1136 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4649727118196105 at step: 1137 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4649301716408933 at step: 1138 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.464887656327379 at step: 1139 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4648451658897315 at step: 1140 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4648027003385358 at step: 1141 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.464760259684294 at step: 1142 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4647178439374327 at step: 1143 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.464675453108296 at step: 1144 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4646330872071518 at step: 1145 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4645907462441863 at step: 1146 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.46454843022951 at step: 1147 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4645061391731513 at step: 1148 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4644638730850614 at step: 1149 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4644216319751115 at step: 1150 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.464379415853099 at step: 1151 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4643372247287367 at step: 1152 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4642950586116616 at step: 1153 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4642529175114356 at step: 1154 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4642108014375377 at step: 1155 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4641687103993737 at step: 1156 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.464126644406265 at step: 1157 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4640846034674635 at step: 1158 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4640425875921377 at step: 1159 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4640005967893812 at step: 1160 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4639586310682096 at step: 1161 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4639166904375593 at step: 1162 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4638747749062944 at step: 1163 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4638328844831987 at step: 1164 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4637910191769774 at step: 1165 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4637491789962638 at step: 1166 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4637073639496108 at step: 1167 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4636655740454958 at step: 1168 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.46362380929232 at step: 1169 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4635820696984096 at step: 1170 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4635403552720123 at step: 1171 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4634986660213007 at step: 1172 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4634570019543733 at step: 1173 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.463415363079249 at step: 1174 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.463373749403874 at step: 1175 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4633321609361187 at step: 1176 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4632905976837773 at step: 1177 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4632490596545689 at step: 1178 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4632075468561372 at step: 1179 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.463166059296052 at step: 1180 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4631245969818067 at step: 1181 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4630831599208198 at step: 1182 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4630417481204367 at step: 1183 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4630003615879277 at step: 1184 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4629590003304878 at step: 1185 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4629176643552375 at step: 1186 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4628763536692244 at step: 1187 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4628350682794213 at step: 1188 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4627938081927276 at step: 1189 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4627525734159676 at step: 1190 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.462711363955893 at step: 1191 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4626701798191821 at step: 1192 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.46262902101244 at step: 1193 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4625878875421945 at step: 1194 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4625467794149072 at step: 1195 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4625056966369616 at step: 1196 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4624646392146687 at step: 1197 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4624236071542682 at step: 1198 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.462382600461927 at step: 1199 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4623416191437395 at step: 1200 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4623006632057247 at step: 1201 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4622597326538336 at step: 1202 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4622188274939423 at step: 1203 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4621779477318557 at step: 1204 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.462137093373307 at step: 1205 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.462096264423958 at step: 1206 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.462055460889396 at step: 1207 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.462014682775141 at step: 1208 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4619739300866386 at step: 1209 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4619332028292638 at step: 1210 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.461892501008321 at step: 1211 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4618518246290442 at step: 1212 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.461811173696594 at step: 1213 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.461770548216062 at step: 1214 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4617299481924695 at step: 1215 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4616893736307666 at step: 1216 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4616488245358332 at step: 1217 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.46160830091248 at step: 1218 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4615678027654446 at step: 1219 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4615273300993976 at step: 1220 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4614868829189394 at step: 1221 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4614464612285978 at step: 1222 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4614060650328362 at step: 1223 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4613656943360434 at step: 1224 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4613253491425418 at step: 1225 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.461285029456584 at step: 1226 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4612447352823534 at step: 1227 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4612044666239643 at step: 1228 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.461164223485463 at step: 1229 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4611240058708264 at step: 1230 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4610838137839621 at step: 1231 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.461043647228711 at step: 1232 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4610035062088456 at step: 1233 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4609633907280686 at step: 1234 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4609233007900162 at step: 1235 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4608832363982582 at step: 1236 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.460843197556292 at step: 1237 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4608031842675517 at step: 1238 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4607631965354018 at step: 1239 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.460723234363142 at step: 1240 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4606832977540007 at step: 1241 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4606433867111428 at step: 1242 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4606035012376657 at step: 1243 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4605636413365988 at step: 1244 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4605238070109046 at step: 1245 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4604839982634814 at step: 1246 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4604442150971588 at step: 1247 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4604044575147017 at step: 1248 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4603647255188075 at step: 1249 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.460325019112109 at step: 1250 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4602853382971728 at step: 1251 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4602456830764994 at step: 1252 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.460206053452524 at step: 1253 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4601664494276156 at step: 1254 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4601268710040802 at step: 1255 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4600873181841563 at step: 1256 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4600477909700185 at step: 1257 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4600082893637762 at step: 1258 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4599688133674733 at step: 1259 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4599293629830914 at step: 1260 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.459889938212545 at step: 1261 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4598505390576866 at step: 1262 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.459811165520302 at step: 1263 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4597718176021166 at step: 1264 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4597324953047874 at step: 1265 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4596931986299118 at step: 1266 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4596539275790197 at step: 1267 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4596146821535816 at step: 1268 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4595754623550012 at step: 1269 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4595362681846205 at step: 1270 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.459497099643719 at step: 1271 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4594579567335118 at step: 1272 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4594188394551508 at step: 1273 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4593797478097295 at step: 1274 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4593406817982733 at step: 1275 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4593016414217481 at step: 1276 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4592626266810576 at step: 1277 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4592236375770427 at step: 1278 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.459184674110483 at step: 1279 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4591457362820948 at step: 1280 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4591068240925347 at step: 1281 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4590679375423963 at step: 1282 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4590290766322127 at step: 1283 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4589902413624558 at step: 1284 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4589514317335346 at step: 1285 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4589126477457999 at step: 1286 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4588738893995379 at step: 1287 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4588351566949798 at step: 1288 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4587964496322905 at step: 1289 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4587577682115755 at step: 1290 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.458719112432885 at step: 1291 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.458680482296202 at step: 1292 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4586418778014543 at step: 1293 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4586032989485087 at step: 1294 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4585647457371702 at step: 1295 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4585262181671879 at step: 1296 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4584877162382486 at step: 1297 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4584492399499802 at step: 1298 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4584107893019531 at step: 1299 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4583723642936768 at step: 1300 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4583339649246014 at step: 1301 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4582955911941213 at step: 1302 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4582572431015701 at step: 1303 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4582189206462222 at step: 1304 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4581806238272954 at step: 1305 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.458142352643949 at step: 1306 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4581041070952825 at step: 1307 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.45806588718034 at step: 1308 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.458027692898107 at step: 1309 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4579895242475103 at step: 1310 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4579513812274203 at step: 1311 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4579132638366503 at step: 1312 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.457875172073954 at step: 1313 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.457837105938032 at step: 1314 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4577990654275246 at step: 1315 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4577610505410175 at step: 1316 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4577230612770375 at step: 1317 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4576850976340572 at step: 1318 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.457647159610491 at step: 1319 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4576092472046986 at step: 1320 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4575713604149834 at step: 1321 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.457533499239592 at step: 1322 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4574956636767153 at step: 1323 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4574578537244889 at step: 1324 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.457420069380993 at step: 1325 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.457382310644253 at step: 1326 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4573445775122367 at step: 1327 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.457306869982859 at step: 1328 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.45726918805398 at step: 1329 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4572315317234035 at step: 1330 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4571939009888806 at step: 1331 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4571562958481048 at step: 1332 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4571187162987174 at step: 1333 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4570811623383073 at step: 1334 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4570436339644037 at step: 1335 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.457006131174487 at step: 1336 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4569686539659832 at step: 1337 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4569312023362604 at step: 1338 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4568937762826386 at step: 1339 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.456856375802381 at step: 1340 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4568190008926982 at step: 1341 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4567816515507481 at step: 1342 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4567443277736358 at step: 1343 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4567070295584132 at step: 1344 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4566697569020781 at step: 1345 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4566325098015789 at step: 1346 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4565952882538098 at step: 1347 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4565580922556107 at step: 1348 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4565209218037725 at step: 1349 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4564837768950336 at step: 1350 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4564466575260782 at step: 1351 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4564095636935421 at step: 1352 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4563724953940071 at step: 1353 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4563354526240038 at step: 1354 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4562984353800128 at step: 1355 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.456261443658462 at step: 1356 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4562244774557294 at step: 1357 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.456187536768141 at step: 1358 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4561506215919742 at step: 1359 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4561137319234523 at step: 1360 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4560768677587521 at step: 1361 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4560400290939968 at step: 1362 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4560032159252612 at step: 1363 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4559664282485694 at step: 1364 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.455929666059895 at step: 1365 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4558929293551657 at step: 1366 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4558562181302512 at step: 1367 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4558195323809813 at step: 1368 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4557828721031307 at step: 1369 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4557462372924261 at step: 1370 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4557096279445454 at step: 1371 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4556730440551167 at step: 1372 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4556364856197215 at step: 1373 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4555999526338903 at step: 1374 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4555634450931059 at step: 1375 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4555269629928023 at step: 1376 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4554905063283674 at step: 1377 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4554540750951377 at step: 1378 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4554176692884035 at step: 1379 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4553812889034075 at step: 1380 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4553449339353446 at step: 1381 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4553086043793617 at step: 1382 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4552723002305576 at step: 1383 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4552360214839855 at step: 1384 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4551997681346507 at step: 1385 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4551635401775107 at step: 1386 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4551273376074771 at step: 1387 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.455091160419415 at step: 1388 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4550550086081426 at step: 1389 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4550188821684302 at step: 1390 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4549827810950027 at step: 1391 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4549467053825418 at step: 1392 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.454910655025678 at step: 1393 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.454874630018999 at step: 1394 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4548386303570475 at step: 1395 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4548026560343177 at step: 1396 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4547667070452603 at step: 1397 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4547307833842793 at step: 1398 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4546948850457366 at step: 1399 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4546590120239444 at step: 1400 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4546231643131733 at step: 1401 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4545873419076485 at step: 1402 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4545515448015494 at step: 1403 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.454515772989012 at step: 1404 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4544800264641269 at step: 1405 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4544443052209417 at step: 1406 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4544086092534583 at step: 1407 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4543729385556365 at step: 1408 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.454337293121391 at step: 1409 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4543016729445928 at step: 1410 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4542660780190686 at step: 1411 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4542305083386033 at step: 1412 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4541949638969387 at step: 1413 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4541594446877704 at step: 1414 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4541239507047554 at step: 1415 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4540884819415028 at step: 1416 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.454053038391583 at step: 1417 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4540176200485226 at step: 1418 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4539822269058038 at step: 1419 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4539468589568691 at step: 1420 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4539115161951177 at step: 1421 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4538761986139055 at step: 1422 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4538409062065492 at step: 1423 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4538056389663208 at step: 1424 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4537703968864517 at step: 1425 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4537351799601317 at step: 1426 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4536999881805102 at step: 1427 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4536648215406935 at step: 1428 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4536296800337476 at step: 1429 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4535945636526981 at step: 1430 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4535594723905287 at step: 1431 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4535244062401824 at step: 1432 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4534893651945617 at step: 1433 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.453454349246529 at step: 1434 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4534193583889061 at step: 1435 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4533843926144745 at step: 1436 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4533494519159744 at step: 1437 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.453314536286109 at step: 1438 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4532796457175385 at step: 1439 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4532447802028854 at step: 1440 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4532099397347316 at step: 1441 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.45317512430562 at step: 1442 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4531403339080535 at step: 1443 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.453105568534497 at step: 1444 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4530708281773754 at step: 1445 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4530361128290743 at step: 1446 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4530014224819432 at step: 1447 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4529667571282878 at step: 1448 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4529321167603808 at step: 1449 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.452897501370454 at step: 1450 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.452862910950699 at step: 1451 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4528283454932727 at step: 1452 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4527938049902924 at step: 1453 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.452759289433837 at step: 1454 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4527247988159486 at step: 1455 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4526903331286314 at step: 1456 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4526558923638517 at step: 1457 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.452621476513539 at step: 1458 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4525870855695855 at step: 1459 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4525527195238452 at step: 1460 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.452518378368137 at step: 1461 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.45248406209424 at step: 1462 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4524497706939008 at step: 1463 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4524155041588263 at step: 1464 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4523812624806873 at step: 1465 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4523470456511196 at step: 1466 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4523128536617198 at step: 1467 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4522786865040527 at step: 1468 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4522445441696443 at step: 1469 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.452210426649985 at step: 1470 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.45217633393653 at step: 1471 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4521422660206982 at step: 1472 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4521082228938744 at step: 1473 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.452074204547407 at step: 1474 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4520402109726096 at step: 1475 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4520062421607602 at step: 1476 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4519722981031027 at step: 1477 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451938378790846 at step: 1478 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451904484215164 at step: 1479 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4518706143671944 at step: 1480 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451836769238044 at step: 1481 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4518029488187838 at step: 1482 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451769153100448 at step: 1483 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4517353820740408 at step: 1484 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4517016357305306 at step: 1485 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4516679140608502 at step: 1486 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451634217055903 at step: 1487 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4516005447065534 at step: 1488 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4515668970036368 at step: 1489 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4515332739379545 at step: 1490 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4514996755002725 at step: 1491 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451466101681325 at step: 1492 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4514325524718141 at step: 1493 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4513990278624083 at step: 1494 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4513655278437425 at step: 1495 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.45133205240642 at step: 1496 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4512986015410123 at step: 1497 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4512651752380572 at step: 1498 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4512317734880598 at step: 1499 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4511983962814963 at step: 1500 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451165043608807 at step: 1501 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451131715460403 at step: 1502 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4510984118266625 at step: 1503 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.451065132697932 at step: 1504 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4510318780645275 at step: 1505 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450998647916732 at step: 1506 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4509654422448004 at step: 1507 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4509322610389517 at step: 1508 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4508991042893777 at step: 1509 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450865971986238 at step: 1510 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4508328641196626 at step: 1511 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4507997806797484 at step: 1512 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4507667216565627 at step: 1513 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450733687040146 at step: 1514 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4507006768205015 at step: 1515 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450667690987609 at step: 1516 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4506347295314141 at step: 1517 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4506017924418333 at step: 1518 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4505688797087555 at step: 1519 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450535991322037 at step: 1520 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4505031272715052 at step: 1521 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450470287546959 at step: 1522 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4504374721381683 at step: 1523 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4504046810348716 at step: 1524 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4503719142267808 at step: 1525 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450339171703577 at step: 1526 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4503064534549135 at step: 1527 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4502737594704136 at step: 1528 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4502410897396742 at step: 1529 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450208444252262 at step: 1530 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4501758229977146 at step: 1531 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450143225965543 at step: 1532 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.450110653145229 at step: 1533 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4500781045262268 at step: 1534 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4500455800979637 at step: 1535 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4500130798498359 at step: 1536 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449980603771216 at step: 1537 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4499481518514457 at step: 1538 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4499157240798408 at step: 1539 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4498833204456898 at step: 1540 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4498509409382536 at step: 1541 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4498185855467656 at step: 1542 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449786254260434 at step: 1543 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449753947068437 at step: 1544 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4497216639599284 at step: 1545 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4496894049240343 at step: 1546 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4496571699498548 at step: 1547 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4496249590264627 at step: 1548 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4495927721429056 at step: 1549 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4495606092882043 at step: 1550 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449528470451354 at step: 1551 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449496355621322 at step: 1552 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4494642647870526 at step: 1553 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4494321979374616 at step: 1554 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4494001550614406 at step: 1555 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449368136147856 at step: 1556 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4493361411855474 at step: 1557 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449304170163331 at step: 1558 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4492722230699953 at step: 1559 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449240299894306 at step: 1560 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4492084006250008 at step: 1561 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449176525250797 at step: 1562 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449144673760384 at step: 1563 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4491128461424259 at step: 1564 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449081042385565 at step: 1565 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.449049262478416 at step: 1566 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4490175064095723 at step: 1567 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4489857741676 at step: 1568 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448954065741045 at step: 1569 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4489223811184249 at step: 1570 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448890720288236 at step: 1571 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.44885908323895 at step: 1572 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4488274699590158 at step: 1573 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4487958804368573 at step: 1574 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448764314660876 at step: 1575 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4487327726194492 at step: 1576 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4487012543009319 at step: 1577 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448669759693656 at step: 1578 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448638288785928 at step: 1579 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4486068415660345 at step: 1580 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4485754180222374 at step: 1581 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448544018142777 at step: 1582 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4485126419158703 at step: 1583 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448481289329712 at step: 1584 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4484499603724743 at step: 1585 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4484186550323064 at step: 1586 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4483873732973371 at step: 1587 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4483561151556716 at step: 1588 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448324880595393 at step: 1589 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4482936696045634 at step: 1590 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4482624821712229 at step: 1591 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.44823131828339 at step: 1592 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4482001779290594 at step: 1593 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4481690610962106 at step: 1594 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448137967772793 at step: 1595 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4481068979467409 at step: 1596 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.448075851605966 at step: 1597 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4480448287383585 at step: 1598 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4480138293317872 at step: 1599 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4479828533741015 at step: 1600 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4479519008531287 at step: 1601 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.447920971756676 at step: 1602 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4478900660725298 at step: 1603 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.447859183788457 at step: 1604 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.447828324892202 at step: 1605 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4477974893714916 at step: 1606 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.44776667721403 at step: 1607 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4477358884075044 at step: 1608 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4477051229395788 at step: 1609 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4476743807978985 at step: 1610 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4476436619700905 at step: 1611 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4476129664437596 at step: 1612 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.447582294206494 at step: 1613 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4475516452458592 at step: 1614 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.447521019549405 at step: 1615 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4474904171046585 at step: 1616 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.447459837899129 at step: 1617 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4474292819203085 at step: 1618 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4473987491556666 at step: 1619 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.447368239592657 at step: 1620 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4473377532187142 at step: 1621 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4473072900212518 at step: 1622 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4472768499876667 at step: 1623 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4472464331053385 at step: 1624 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4472160393616254 at step: 1625 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4471856687438693 at step: 1626 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4471553212393944 at step: 1627 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4471249968355053 at step: 1628 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4470946955194899 at step: 1629 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4470644172786167 at step: 1630 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4470341621001386 at step: 1631 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4470039299712878 at step: 1632 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4469737208792828 at step: 1633 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4469435348113202 at step: 1634 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446913371754583 at step: 1635 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4468832316962357 at step: 1636 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446853114623424 at step: 1637 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446823020523279 at step: 1638 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4467929493829124 at step: 1639 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4467629011894207 at step: 1640 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446732875929882 at step: 1641 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4467028735913599 at step: 1642 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4466728941608993 at step: 1643 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4466429376255294 at step: 1644 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446613003972263 at step: 1645 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446583093188096 at step: 1646 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4465532052600083 at step: 1647 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4465233401749646 at step: 1648 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446493497919911 at step: 1649 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4464636784817804 at step: 1650 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446433881847488 at step: 1651 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4464041080039345 at step: 1652 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4463743569380028 at step: 1653 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4463446286365624 at step: 1654 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4463149230864658 at step: 1655 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4462852402745512 at step: 1656 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4462555801876402 at step: 1657 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4462259428125401 at step: 1658 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446196328136043 at step: 1659 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.446166736144924 at step: 1660 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4461371668259466 at step: 1661 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4461076201658558 at step: 1662 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4460780961513848 at step: 1663 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4460485947692496 at step: 1664 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4460191160061542 at step: 1665 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4459896598487856 at step: 1666 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445960226283817 at step: 1667 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4459308152979076 at step: 1668 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4459014268777024 at step: 1669 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4458720610098321 at step: 1670 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445842717680912 at step: 1671 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4458133968775464 at step: 1672 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445784098586322 at step: 1673 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4457548227938142 at step: 1674 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445725569486584 at step: 1675 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4456963386511767 at step: 1676 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445667130274129 at step: 1677 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4456379443419585 at step: 1678 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4456087808411726 at step: 1679 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4455796397582632 at step: 1680 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4455505210797113 at step: 1681 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445521424791985 at step: 1682 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4454923508815363 at step: 1683 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4454632993348053 at step: 1684 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4454342701382212 at step: 1685 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445405263278198 at step: 1686 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4453762787411386 at step: 1687 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4453473165134314 at step: 1688 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445318376581454 at step: 1689 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4452894589315708 at step: 1690 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4452605635501339 at step: 1691 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4452316904234828 at step: 1692 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4452028395379442 at step: 1693 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445174010879834 at step: 1694 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4451452044354556 at step: 1695 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4451164201910998 at step: 1696 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4450876581330445 at step: 1697 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4450589182475584 at step: 1698 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4450302005208973 at step: 1699 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.445001504939305 at step: 1700 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4449728314890122 at step: 1701 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.444944180156242 at step: 1702 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.444915550927203 at step: 1703 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4448869437880913 at step: 1704 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.444858358725096 at step: 1705 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4448297957243912 at step: 1706 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4448012547721423 at step: 1707 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4447727358545022 at step: 1708 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4447442389576128 at step: 1709 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4447157640676065 at step: 1710 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4446873111706027 at step: 1711 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4446588802527125 at step: 1712 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.444630471300035 at step: 1713 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.444602084298659 at step: 1714 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4445737192346628 at step: 1715 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4445453760941145 at step: 1716 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4445170548630708 at step: 1717 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4444887555275798 at step: 1718 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4444604780736792 at step: 1719 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4444322224873942 at step: 1720 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4444039887547433 at step: 1721 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4443757768617331 at step: 1722 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.444347586794361 at step: 1723 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4443194185386137 at step: 1724 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4442912720804697 at step: 1725 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4442631474058973 at step: 1726 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4442350445008534 at step: 1727 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4442069633512893 at step: 1728 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4441789039431432 at step: 1729 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4441508662623457 at step: 1730 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4441228502948174 at step: 1731 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.44409485602647 at step: 1732 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4440668834432073 at step: 1733 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4440389325309213 at step: 1734 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4440110032754983 at step: 1735 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4439830956628135 at step: 1736 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4439552096787343 at step: 1737 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.443927345309118 at step: 1738 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4438995025398147 at step: 1739 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4438716813566652 at step: 1740 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4438438817455022 at step: 1741 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4438161036921495 at step: 1742 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4437883471824233 at step: 1743 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4437606122021305 at step: 1744 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4437328987370701 at step: 1745 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.443705206773033 at step: 1746 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4436775362958019 at step: 1747 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.443649887291153 at step: 1748 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4436222597448511 at step: 1749 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.443594653642656 at step: 1750 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4435670689703204 at step: 1751 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4435395057135854 at step: 1752 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4435119638581881 at step: 1753 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4434844433898566 at step: 1754 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.443456944294311 at step: 1755 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4434294665572656 at step: 1756 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4434020101644256 at step: 1757 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.443374575101489 at step: 1758 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4433471613541489 at step: 1759 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4433197689080872 at step: 1760 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4432923977489822 at step: 1761 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.443265047862504 at step: 1762 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.443237719234315 at step: 1763 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4432104118500715 at step: 1764 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4431831256954228 at step: 1765 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4431558607560113 at step: 1766 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4431286170174726 at step: 1767 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4431013944654372 at step: 1768 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4430741930855266 at step: 1769 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4430470128633563 at step: 1770 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4430198537845371 at step: 1771 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442992715834673 at step: 1772 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442965598999359 at step: 1773 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442938503264188 at step: 1774 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4429114286147426 at step: 1775 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4428843750366034 at step: 1776 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4428573425153421 at step: 1777 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4428303310365247 at step: 1778 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4428033405857132 at step: 1779 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4427763711484605 at step: 1780 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4427494227103175 at step: 1781 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4427224952568274 at step: 1782 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4426955887735269 at step: 1783 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4426687032459493 at step: 1784 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4426418386596203 at step: 1785 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4426149950000615 at step: 1786 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4425881722527885 at step: 1787 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4425613704033133 at step: 1788 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442534589437139 at step: 1789 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4425078293397675 at step: 1790 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442481090096692 at step: 1791 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442454371693404 at step: 1792 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4424276741153874 at step: 1793 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4424009973481229 at step: 1794 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4423743413770842 at step: 1795 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4423477061877439 at step: 1796 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442321091765565 at step: 1797 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4422944980960104 at step: 1798 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442267925164534 at step: 1799 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4422413729565904 at step: 1800 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4422148414576246 at step: 1801 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4421883306530794 at step: 1802 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4421618405283936 at step: 1803 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442135371069001 at step: 1804 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4421089222603323 at step: 1805 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442082494087811 at step: 1806 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.44205608653686 at step: 1807 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442029699592896 at step: 1808 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.442003333241333 at step: 1809 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4419769874675792 at step: 1810 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4419506622570408 at step: 1811 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4419243575951193 at step: 1812 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4418980734672115 at step: 1813 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4418718098587133 at step: 1814 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4418455667550139 at step: 1815 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4418193441415001 at step: 1816 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.441793142003555 at step: 1817 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4417669603265588 at step: 1818 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4417407990958877 at step: 1819 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4417146582969147 at step: 1820 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4416885379150095 at step: 1821 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4416624379355378 at step: 1822 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4416363583438634 at step: 1823 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4416102991253459 at step: 1824 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4415842602653433 at step: 1825 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4415582417492079 at step: 1826 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4415322435622913 at step: 1827 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4415062656899424 at step: 1828 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.441480308117505 at step: 1829 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4414543708303218 at step: 1830 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4414284538137325 at step: 1831 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4414025570530742 at step: 1832 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4413766805336807 at step: 1833 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4413508242408846 at step: 1834 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4413249881600134 at step: 1835 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.441299172276395 at step: 1836 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4412733765753538 at step: 1837 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4412476010422104 at step: 1838 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4412218456622863 at step: 1839 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4411961104208968 at step: 1840 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4411703953033586 at step: 1841 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4411447002949833 at step: 1842 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4411190253810824 at step: 1843 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4410933705469653 at step: 1844 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4410677357779376 at step: 1845 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4410421210593052 at step: 1846 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4410165263763703 at step: 1847 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.440990951714435 at step: 1848 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.440965397058798 at step: 1849 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4409398623947574 at step: 1850 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4409143477076092 at step: 1851 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4408888529826474 at step: 1852 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4408633782051654 at step: 1853 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4408379233604531 at step: 1854 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4408124884338034 at step: 1855 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4407870734105015 at step: 1856 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4407616782758357 at step: 1857 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4407363030150926 at step: 1858 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4407109476135553 at step: 1859 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4406856120565084 at step: 1860 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4406602963292336 at step: 1861 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4406350004170108 at step: 1862 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4406097243051215 at step: 1863 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4405844679788444 at step: 1864 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4405592314234572 at step: 1865 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.440534014624237 at step: 1866 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4405088175664602 at step: 1867 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4404836402354024 at step: 1868 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4404584826163378 at step: 1869 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.440433344694541 at step: 1870 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.440408226455284 at step: 1871 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4403831278838424 at step: 1872 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4403580489654857 at step: 1873 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4403329896854855 at step: 1874 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4403079500291145 at step: 1875 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.440282929981643 at step: 1876 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4402579295283406 at step: 1877 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4402329486544787 at step: 1878 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4402079873453255 at step: 1879 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4401830455861524 at step: 1880 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4401581233622271 at step: 1881 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4401332206588195 at step: 1882 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4401083374611994 at step: 1883 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4400834737546346 at step: 1884 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4400586295243956 at step: 1885 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4400338047557506 at step: 1886 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4400089994339695 at step: 1887 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.439984213544321 at step: 1888 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4399594470720758 at step: 1889 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4399347000025033 at step: 1890 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4399099723208728 at step: 1891 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4398852640124566 at step: 1892 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4398605750625237 at step: 1893 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4398359054563463 at step: 1894 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4398112551791964 at step: 1895 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.439786624216346 at step: 1896 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4397620125530677 at step: 1897 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.439737420174635 at step: 1898 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4397128470663219 at step: 1899 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4396882932134036 at step: 1900 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4396637586011551 at step: 1901 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4396392432148528 at step: 1902 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4396147470397742 at step: 1903 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4395902700611962 at step: 1904 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4395658122643984 at step: 1905 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4395413736346607 at step: 1906 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4395169541572637 at step: 1907 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4394925538174892 at step: 1908 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4394681726006202 at step: 1909 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4394438104919407 at step: 1910 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4394194674767358 at step: 1911 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4393951435402923 at step: 1912 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4393708386678976 at step: 1913 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4393465528448404 at step: 1914 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4393222860564112 at step: 1915 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4392980382879013 at step: 1916 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4392738095246052 at step: 1917 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.439249599751815 at step: 1918 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4392254089548298 at step: 1919 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4392012371189442 at step: 1920 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4391770842294593 at step: 1921 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4391529502716751 at step: 1922 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.439128835230894 at step: 1923 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4391047390924208 at step: 1924 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4390806618415604 at step: 1925 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4390566034636216 at step: 1926 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4390325639439134 at step: 1927 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.439008543267747 at step: 1928 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4389845414204356 at step: 1929 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4389605583872949 at step: 1930 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4389365941536412 at step: 1931 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4389126487047956 at step: 1932 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4388887220260775 at step: 1933 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.438864814102811 at step: 1934 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.438840924920322 at step: 1935 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.438817054463938 at step: 1936 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4387932027189883 at step: 1937 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4387693696708062 at step: 1938 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4387455553047253 at step: 1939 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4387217596060824 at step: 1940 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.438697982560217 at step: 1941 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4386742241524713 at step: 1942 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4386504843681887 at step: 1943 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4386267631927159 at step: 1944 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4386030606114013 at step: 1945 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.438579376609598 at step: 1946 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4385557111726592 at step: 1947 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4385320642859414 at step: 1948 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4385084359348055 at step: 1949 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4384848261046121 at step: 1950 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.438461234780727 at step: 1951 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4384376619485182 at step: 1952 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4384141075933559 at step: 1953 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4383905717006136 at step: 1954 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4383670542556681 at step: 1955 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4383435552438977 at step: 1956 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4383200746506846 at step: 1957 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4382966124614156 at step: 1958 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4382731686614778 at step: 1959 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.438249743236262 at step: 1960 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4382263361711634 at step: 1961 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4382029474515794 at step: 1962 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4381795770629107 at step: 1963 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4381562249905608 at step: 1964 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4381328912199378 at step: 1965 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.438109575736451 at step: 1966 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4380862785255153 at step: 1967 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4380629995725474 at step: 1968 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4380397388629673 at step: 1969 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4380164963821993 at step: 1970 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4379932721156714 at step: 1971 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4379700660488133 at step: 1972 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4379468781670603 at step: 1973 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4379237084558496 at step: 1974 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437900556900623 at step: 1975 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437877423486825 at step: 1976 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4378543081999051 at step: 1977 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4378312110253162 at step: 1978 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4378081319485134 at step: 1979 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437785070954957 at step: 1980 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4377620280301113 at step: 1981 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4377390031594417 at step: 1982 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4377159963284223 at step: 1983 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4376930075225265 at step: 1984 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4376700367272337 at step: 1985 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4376470839280275 at step: 1986 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437624149110394 at step: 1987 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437601232259826 at step: 1988 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4375783333618168 at step: 1989 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4375554524018659 at step: 1990 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4375325893654776 at step: 1991 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4375097442381577 at step: 1992 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4374869170054188 at step: 1993 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4374641076527763 at step: 1994 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4374413161657502 at step: 1995 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4374185425298642 at step: 1996 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4373957867306482 at step: 1997 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4373730487536338 at step: 1998 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4373503285843579 at step: 1999 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4373276262083627 at step: 2000 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4373049416111938 at step: 2001 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437282274778402 at step: 2002 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4372596256955414 at step: 2003 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4372369943481718 at step: 2004 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4372143807218571 at step: 2005 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437191784802165 at step: 2006 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4371692065746695 at step: 2007 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4371466460249473 at step: 2008 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4371241031385806 at step: 2009 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4371015779011573 at step: 2010 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437079070298268 at step: 2011 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.437056580315509 at step: 2012 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4370341079384823 at step: 2013 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4370116531527928 at step: 2014 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4369892159440512 at step: 2015 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436966796297873 at step: 2016 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4369443941998796 at step: 2017 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4369220096356947 at step: 2018 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4368996425909495 at step: 2019 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4368772930512785 at step: 2020 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436854961002322 at step: 2021 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4368326464297252 at step: 2022 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4368103493191384 at step: 2023 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4367880696562179 at step: 2024 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4367658074266214 at step: 2025 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4367435626160154 at step: 2026 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4367213352100718 at step: 2027 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4366991251944645 at step: 2028 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4366769325548747 at step: 2029 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4366547572769894 at step: 2030 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4366325993464995 at step: 2031 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4366104587491013 at step: 2032 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4365883354704978 at step: 2033 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4365662294963948 at step: 2034 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4365441408125057 at step: 2035 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4365220694045486 at step: 2036 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4365000152582466 at step: 2037 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436477978359329 at step: 2038 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436455958693529 at step: 2039 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4364339562465878 at step: 2040 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4364119710042493 at step: 2041 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4363900029522654 at step: 2042 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436368052076391 at step: 2043 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43634611836239 at step: 2044 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436324201796028 at step: 2045 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4363023023630803 at step: 2046 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4362804200493229 at step: 2047 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4362585548405424 at step: 2048 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4362367067225286 at step: 2049 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436214875681077 at step: 2050 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436193061701989 at step: 2051 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4361712647710732 at step: 2052 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4361494848741416 at step: 2053 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436127721997014 at step: 2054 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4361059761255148 at step: 2055 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4360842472454751 at step: 2056 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4360625353427316 at step: 2057 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436040840403126 at step: 2058 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.436019162412508 at step: 2059 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435997501356732 at step: 2060 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4359758572216568 at step: 2061 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4359542299931514 at step: 2062 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4359326196570863 at step: 2063 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4359110261993409 at step: 2064 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4358894496057995 at step: 2065 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435867889862353 at step: 2066 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435846346954898 at step: 2067 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4358248208693378 at step: 2068 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435803311591581 at step: 2069 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4357818191075435 at step: 2070 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4357603434031472 at step: 2071 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4357388844643186 at step: 2072 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4357174422769927 at step: 2073 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43569601682711 at step: 2074 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4356746081006158 at step: 2075 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4356532160834639 at step: 2076 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435631840761614 at step: 2077 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4356104821210312 at step: 2078 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435589140147687 at step: 2079 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4355678148275601 at step: 2080 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4355465061466357 at step: 2081 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4355252140909047 at step: 2082 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4355039386463646 at step: 2083 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43548267979902 at step: 2084 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4354614375348818 at step: 2085 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4354402118399667 at step: 2086 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4354190027002987 at step: 2087 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4353978101019078 at step: 2088 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4353766340308312 at step: 2089 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4353554744731125 at step: 2090 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4353343314148017 at step: 2091 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4353132048419563 at step: 2092 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4352920947406385 at step: 2093 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4352710010969192 at step: 2094 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4352499238968752 at step: 2095 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4352288631265904 at step: 2096 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4352078187721546 at step: 2097 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4351867908196645 at step: 2098 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4351657792552248 at step: 2099 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435144784064946 at step: 2100 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4351238052349446 at step: 2101 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4351028427513466 at step: 2102 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4350818966002818 at step: 2103 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4350609667678893 at step: 2104 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435040053240313 at step: 2105 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.435019156003705 at step: 2106 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4349982750442245 at step: 2107 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434977410348037 at step: 2108 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4349565619013156 at step: 2109 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4349357296902396 at step: 2110 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4349149137009953 at step: 2111 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434894113919777 at step: 2112 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4348733303327852 at step: 2113 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4348525629262279 at step: 2114 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4348318116863195 at step: 2115 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4348110765992832 at step: 2116 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434790357651346 at step: 2117 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4347696548287465 at step: 2118 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4347489681177266 at step: 2119 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434728297504536 at step: 2120 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4347076429754337 at step: 2121 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4346870045166846 at step: 2122 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4346663821145609 at step: 2123 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4346457757553408 at step: 2124 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4346251854253125 at step: 2125 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4346046111107678 at step: 2126 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4345840527980096 at step: 2127 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4345635104733452 at step: 2128 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4345429841230906 at step: 2129 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4345224737335691 at step: 2130 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434501979291111 at step: 2131 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4344815007820537 at step: 2132 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434461038192743 at step: 2133 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4344405915095302 at step: 2134 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4344201607187768 at step: 2135 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4343997458068487 at step: 2136 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4343793467601214 at step: 2137 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4343589635649765 at step: 2138 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4343385962078046 at step: 2139 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4343182446750025 at step: 2140 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4342979089529746 at step: 2141 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4342775890281325 at step: 2142 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4342572848868982 at step: 2143 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4342369965156965 at step: 2144 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4342167239009629 at step: 2145 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4341964670291412 at step: 2146 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434176225886679 at step: 2147 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434156000460036 at step: 2148 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434135790735676 at step: 2149 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4341155967000725 at step: 2150 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4340954183397059 at step: 2151 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.434075255641064 at step: 2152 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4340551085906434 at step: 2153 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4340349771749465 at step: 2154 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4340148613804857 at step: 2155 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433994761193779 at step: 2156 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4339746766013544 at step: 2157 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4339546075897447 at step: 2158 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4339345541454926 at step: 2159 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4339145162551488 at step: 2160 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4338944939052698 at step: 2161 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4338744870824223 at step: 2162 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4338544957731785 at step: 2163 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4338345199641207 at step: 2164 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4338145596418372 at step: 2165 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4337946147929257 at step: 2166 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43377468540399 at step: 2167 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4337547714616423 at step: 2168 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4337348729525048 at step: 2169 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433714989863205 at step: 2170 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4336951221803789 at step: 2171 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4336752698906712 at step: 2172 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4336554329807343 at step: 2173 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4336356114372282 at step: 2174 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4336158052468206 at step: 2175 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4335960143961874 at step: 2176 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4335762388720144 at step: 2177 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4335564786609925 at step: 2178 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433536733749821 at step: 2179 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43351700412521 at step: 2180 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4334972897738747 at step: 2181 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433477590682539 at step: 2182 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433457906837936 at step: 2183 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4334382382268054 at step: 2184 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4334185848358962 at step: 2185 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433398946651965 at step: 2186 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4333793236617773 at step: 2187 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4333597158521036 at step: 2188 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433340123209727 at step: 2189 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4333205457214353 at step: 2190 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4333009833740278 at step: 2191 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4332814361543078 at step: 2192 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4332619040490893 at step: 2193 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4332423870451954 at step: 2194 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4332228851294553 at step: 2195 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433203398288707 at step: 2196 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4331839265097972 at step: 2197 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4331644697795807 at step: 2198 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4331450280849207 at step: 2199 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433125601412688 at step: 2200 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4331061897497621 at step: 2201 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.433086793083031 at step: 2202 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4330674113993909 at step: 2203 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4330480446857456 at step: 2204 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4330286929290081 at step: 2205 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4330093561160997 at step: 2206 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4329900342339483 at step: 2207 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432970727269494 at step: 2208 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432951435209681 at step: 2209 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4329321580414633 at step: 2210 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4329128957518051 at step: 2211 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4328936483276766 at step: 2212 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4328744157560573 at step: 2213 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4328551980239355 at step: 2214 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432835995118307 at step: 2215 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432816807026177 at step: 2216 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4327976337345592 at step: 2217 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432778475230473 at step: 2218 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432759331500951 at step: 2219 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4327402025330298 at step: 2220 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4327210883137576 at step: 2221 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4327019888301895 at step: 2222 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4326829040693891 at step: 2223 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4326638340184286 at step: 2224 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4326447786643899 at step: 2225 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432625737994361 at step: 2226 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4326067119954409 at step: 2227 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4325877006547363 at step: 2228 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432568703959361 at step: 2229 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4325497218964394 at step: 2230 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4325307544531036 at step: 2231 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432511801616494 at step: 2232 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4324928633737597 at step: 2233 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4324739397120583 at step: 2234 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4324550306185568 at step: 2235 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43243613608043 at step: 2236 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4324172560848616 at step: 2237 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432398390619043 at step: 2238 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4323795396701757 at step: 2239 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43236070322547 at step: 2240 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432341881272142 at step: 2241 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4323230737974195 at step: 2242 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4323042807885378 at step: 2243 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432285502232741 at step: 2244 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4322667381172813 at step: 2245 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4322479884294212 at step: 2246 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4322292531564296 at step: 2247 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432210532285586 at step: 2248 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4321918258041773 at step: 2249 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4321731336994992 at step: 2250 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4321544559588575 at step: 2251 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4321357925695657 at step: 2252 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4321171435189455 at step: 2253 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4320985087943283 at step: 2254 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4320798883830532 at step: 2255 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4320612822724696 at step: 2256 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4320426904499342 at step: 2257 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.432024112902813 at step: 2258 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4320055496184811 at step: 2259 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431987000584322 at step: 2260 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4319684657877276 at step: 2261 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4319499452161 at step: 2262 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4319314388568478 at step: 2263 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4319129466973908 at step: 2264 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4318944687251551 at step: 2265 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4318760049275783 at step: 2266 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4318575552921053 at step: 2267 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4318391198061904 at step: 2268 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4318206984572954 at step: 2269 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4318022912328927 at step: 2270 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4317838981204625 at step: 2271 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4317655191074943 at step: 2272 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4317471541814863 at step: 2273 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4317288033299447 at step: 2274 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4317104665403866 at step: 2275 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4316921438003358 at step: 2276 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431673835097327 at step: 2277 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4316555404189022 at step: 2278 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4316372597526126 at step: 2279 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4316189930860188 at step: 2280 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4316007404066897 at step: 2281 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4315825017022035 at step: 2282 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4315642769601489 at step: 2283 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4315460661681192 at step: 2284 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4315278693137208 at step: 2285 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431509686384567 at step: 2286 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4314915173682812 at step: 2287 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4314733622524942 at step: 2288 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4314552210248475 at step: 2289 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43143709367299 at step: 2290 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431418980184581 at step: 2291 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4314008805472869 at step: 2292 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4313827947487852 at step: 2293 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4313647227767603 at step: 2294 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431346664618908 at step: 2295 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43132862026293 at step: 2296 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4313105896965403 at step: 2297 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4312925729074597 at step: 2298 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4312745698834168 at step: 2299 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431256580612154 at step: 2300 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4312386050814179 at step: 2301 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4312206432789654 at step: 2302 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4312026951925634 at step: 2303 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431184760809988 at step: 2304 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4311668401190223 at step: 2305 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4311489331074612 at step: 2306 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4311310397631054 at step: 2307 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431113160073767 at step: 2308 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4310952940272679 at step: 2309 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431077441611435 at step: 2310 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4310596028141094 at step: 2311 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4310417776231372 at step: 2312 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4310239660263764 at step: 2313 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.431006168011691 at step: 2314 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430988383566957 at step: 2315 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4309706126800579 at step: 2316 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430952855338886 at step: 2317 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4309351115313451 at step: 2318 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4309173812453442 at step: 2319 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4308996644688043 at step: 2320 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4308819611896557 at step: 2321 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4308642713958348 at step: 2322 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4308465950752902 at step: 2323 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4308289322159782 at step: 2324 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4308112828058634 at step: 2325 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4307936468329223 at step: 2326 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4307760242851373 at step: 2327 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430758415150502 at step: 2328 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4307408194170175 at step: 2329 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4307232370726952 at step: 2330 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430705668105556 at step: 2331 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430688112503629 at step: 2332 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4306705702549518 at step: 2333 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4306530413475729 at step: 2334 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4306355257695487 at step: 2335 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4306180235089447 at step: 2336 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430600534553837 at step: 2337 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4305830588923083 at step: 2338 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4305655965124522 at step: 2339 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4305481474023716 at step: 2340 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430530711550177 at step: 2341 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4305132889439904 at step: 2342 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4304958795719402 at step: 2343 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4304784834221664 at step: 2344 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4304611004828165 at step: 2345 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430443730742048 at step: 2346 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4304263741880265 at step: 2347 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4304090308089283 at step: 2348 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4303917005929385 at step: 2349 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4303743835282505 at step: 2350 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4303570796030678 at step: 2351 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430339788805602 at step: 2352 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430322511124074 at step: 2353 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4303052465467156 at step: 2354 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4302879950617648 at step: 2355 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4302707566574733 at step: 2356 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4302535313220965 at step: 2357 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4302363190439034 at step: 2358 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4302191198111687 at step: 2359 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4302019336121794 at step: 2360 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4301847604352298 at step: 2361 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4301676002686243 at step: 2362 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430150453100676 at step: 2363 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4301333189197059 at step: 2364 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4301161977140473 at step: 2365 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43009908947204 at step: 2366 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4300819941820349 at step: 2367 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.43006491183239 at step: 2368 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.430047842411474 at step: 2369 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4300307859076642 at step: 2370 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4300137423093484 at step: 2371 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429996711604921 at step: 2372 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4299796937827887 at step: 2373 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4299626888313646 at step: 2374 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4299456967390725 at step: 2375 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429928717494346 at step: 2376 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4299117510856256 at step: 2377 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4298947975013632 at step: 2378 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4298778567300199 at step: 2379 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429860928760064 at step: 2380 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429844013579975 at step: 2381 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4298271111782401 at step: 2382 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429810221543358 at step: 2383 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429793344663834 at step: 2384 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4297764805281838 at step: 2385 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4297596291249326 at step: 2386 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4297427904426145 at step: 2387 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4297259644697726 at step: 2388 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4297091511949591 at step: 2389 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4296923506067365 at step: 2390 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4296755626936748 at step: 2391 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4296587874443552 at step: 2392 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4296420248473662 at step: 2393 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4296252748913068 at step: 2394 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4296085375647842 at step: 2395 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4295918128564165 at step: 2396 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4295751007548296 at step: 2397 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429558401248658 at step: 2398 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429541714326548 at step: 2399 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429525039977153 at step: 2400 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4295083781891358 at step: 2401 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429491728951168 at step: 2402 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4294750922519324 at step: 2403 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4294584680801194 at step: 2404 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4294418564244298 at step: 2405 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4294252572735715 at step: 2406 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429408670616264 at step: 2407 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429392096441235 at step: 2408 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4293755347372203 at step: 2409 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4293589854929676 at step: 2410 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4293424486972313 at step: 2411 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4293259243387761 at step: 2412 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4293094124063768 at step: 2413 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4292929128888148 at step: 2414 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429276425774883 at step: 2415 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4292599510533837 at step: 2416 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429243488713127 at step: 2417 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4292270387429322 at step: 2418 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.42921060113163 at step: 2419 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4291941758680569 at step: 2420 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4291777629410625 at step: 2421 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429161362339502 at step: 2422 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429144974052242 at step: 2423 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4291285980681585 at step: 2424 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4291122343761344 at step: 2425 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4290958829650646 at step: 2426 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.429079543823852 at step: 2427 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4290632169414077 at step: 2428 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4290469023066543 at step: 2429 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4290305999085218 at step: 2430 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4290143097359498 at step: 2431 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4289980317778874 at step: 2432 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4289817660232926 at step: 2433 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4289655124611336 at step: 2434 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4289492710803864 at step: 2435 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4289330418700366 at step: 2436 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4289168248190798 at step: 2437 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4289006199165193 at step: 2438 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4288844271513699 at step: 2439 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4288682465126539 at step: 2440 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428852077989402 at step: 2441 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428835921570657 at step: 2442 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4288197772454678 at step: 2443 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4288036450028945 at step: 2444 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4287875248320059 at step: 2445 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4287714167218788 at step: 2446 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428755320661602 at step: 2447 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4287392366402707 at step: 2448 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4287231646469907 at step: 2449 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428707104670876 at step: 2450 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4286910567010518 at step: 2451 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4286750207266492 at step: 2452 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4286589967368122 at step: 2453 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4286429847206914 at step: 2454 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4286269846674475 at step: 2455 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4286109965662503 at step: 2456 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4285950204062794 at step: 2457 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428579056176722 at step: 2458 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4285631038667759 at step: 2459 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4285471634656473 at step: 2460 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4285312349625527 at step: 2461 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4285153183467165 at step: 2462 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428499413607373 at step: 2463 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4284835207337643 at step: 2464 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4284676397151441 at step: 2465 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4284517705407738 at step: 2466 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4284359131999236 at step: 2467 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428420067681874 at step: 2468 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4284042339759133 at step: 2469 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4283884120713402 at step: 2470 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4283726019574625 at step: 2471 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4283568036235958 at step: 2472 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4283410170590671 at step: 2473 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4283252422532102 at step: 2474 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4283094791953697 at step: 2475 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4282937278748977 at step: 2476 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4282779882811576 at step: 2477 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4282622604035216 at step: 2478 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428246544231368 at step: 2479 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428230839754089 at step: 2480 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4282151469610813 at step: 2481 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4281994658417543 at step: 2482 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4281837963855253 at step: 2483 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4281681385818197 at step: 2484 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4281524924200732 at step: 2485 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4281368578897307 at step: 2486 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428121234980246 at step: 2487 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428105623681081 at step: 2488 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428090023981709 at step: 2489 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4280744358716102 at step: 2490 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4280588593402748 at step: 2491 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.428043294377202 at step: 2492 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4280277409719002 at step: 2493 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4280121991138877 at step: 2494 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4279966687926897 at step: 2495 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4279811499978439 at step: 2496 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4279656427188936 at step: 2497 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4279501469453926 at step: 2498 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4279346626669052 at step: 2499 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427919189873002 at step: 2500 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4279037285532659 at step: 2501 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4278882786972855 at step: 2502 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4278728402946612 at step: 2503 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427857413335001 at step: 2504 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427841997807923 at step: 2505 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4278265937030539 at step: 2506 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4278112010100292 at step: 2507 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4277958197184932 at step: 2508 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4277804498181 at step: 2509 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4277650912985131 at step: 2510 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4277497441494038 at step: 2511 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4277344083604537 at step: 2512 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4277190839213527 at step: 2513 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4277037708218 at step: 2514 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4276884690515033 at step: 2515 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4276731786001804 at step: 2516 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4276578994575582 at step: 2517 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427642631613371 at step: 2518 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4276273750573636 at step: 2519 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.42761212977929 at step: 2520 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4275968957689118 at step: 2521 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4275816730160011 at step: 2522 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4275664615103385 at step: 2523 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4275512612417132 at step: 2524 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4275360721999237 at step: 2525 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4275208943747781 at step: 2526 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4275057277560934 at step: 2527 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4274905723336944 at step: 2528 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427475428097416 at step: 2529 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4274602950371025 at step: 2530 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4274451731426052 at step: 2531 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4274300624037872 at step: 2532 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4274149628105182 at step: 2533 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4273998743526786 at step: 2534 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4273847970201567 at step: 2535 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4273697308028503 at step: 2536 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4273546756906663 at step: 2537 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4273396316735192 at step: 2538 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427324598741335 at step: 2539 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427309576884046 at step: 2540 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4272945660915959 at step: 2541 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427279566353936 at step: 2542 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4272645776610262 at step: 2543 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4272496000028358 at step: 2544 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4272346333693438 at step: 2545 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4272196777505375 at step: 2546 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.427204733136413 at step: 2547 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4271897995169756 at step: 2548 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4271748768822392 at step: 2549 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4271599652222278 at step: 2550 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4271450645269728 at step: 2551 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4271301747865155 at step: 2552 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4271152959909048 at step: 2553 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4271004281302002 at step: 2554 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4270855711944705 at step: 2555 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4270707251737904 at step: 2556 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4270558900582475 at step: 2557 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4270410658379353 at step: 2558 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4270262525029573 at step: 2559 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4270114500434254 at step: 2560 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4269966584494616 at step: 2561 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4269818777111956 at step: 2562 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4269671078187665 at step: 2563 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4269523487623217 at step: 2564 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426937600532019 at step: 2565 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4269228631180226 at step: 2566 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4269081365105083 at step: 2567 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4268934206996595 at step: 2568 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426878715675668 at step: 2569 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426864021428734 at step: 2570 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4268493379490697 at step: 2571 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4268346652268915 at step: 2572 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4268200032524287 at step: 2573 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4268053520159178 at step: 2574 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426790711507604 at step: 2575 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4267760817177402 at step: 2576 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4267614626365914 at step: 2577 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4267468542544282 at step: 2578 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4267322565615321 at step: 2579 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4267176695481925 at step: 2580 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4267030932047073 at step: 2581 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4266885275213843 at step: 2582 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4266739724885384 at step: 2583 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4266594280964964 at step: 2584 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4266448943355894 at step: 2585 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4266303711961617 at step: 2586 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4266158586685638 at step: 2587 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426601356743155 at step: 2588 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4265868654103055 at step: 2589 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426572384660392 at step: 2590 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4265579144838003 at step: 2591 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426543454870927 at step: 2592 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4265290058121747 at step: 2593 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4265145672979558 at step: 2594 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4265001393186933 at step: 2595 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4264857218648161 at step: 2596 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426471314926763 at step: 2597 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4264569184949825 at step: 2598 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4264425325599301 at step: 2599 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426428157112071 at step: 2600 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4264137921418785 at step: 2601 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4263994376398377 at step: 2602 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4263850935964377 at step: 2603 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4263707600021789 at step: 2604 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.42635643684757 at step: 2605 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4263421241231284 at step: 2606 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4263278218193807 at step: 2607 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4263135299268617 at step: 2608 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4262992484361148 at step: 2609 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426284977337692 at step: 2610 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426270716622155 at step: 2611 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4262564662800725 at step: 2612 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4262422263020231 at step: 2613 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4262279966785947 at step: 2614 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4262137774003816 at step: 2615 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4261995684579891 at step: 2616 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4261853698420293 at step: 2617 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4261711815431244 at step: 2618 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.426157003551905 at step: 2619 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4261428358590087 at step: 2620 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4261286784550848 at step: 2621 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4261145313307886 at step: 2622 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4261003944767847 at step: 2623 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4260862678837471 at step: 2624 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4260721515423576 at step: 2625 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4260580454433074 at step: 2626 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4260439495772956 at step: 2627 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4260298639350297 at step: 2628 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4260157885072267 at step: 2629 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4260017232846116 at step: 2630 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4259876682579182 at step: 2631 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4259736234178884 at step: 2632 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4259595887552738 at step: 2633 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4259455642608339 at step: 2634 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4259315499253364 at step: 2635 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425917545739558 at step: 2636 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4259035516942835 at step: 2637 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4258895677803078 at step: 2638 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4258755939884316 at step: 2639 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4258616303094673 at step: 2640 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4258476767342338 at step: 2641 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4258337332535589 at step: 2642 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4258197998582793 at step: 2643 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4258058765392396 at step: 2644 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4257919632872946 at step: 2645 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425778060093305 at step: 2646 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4257641669481425 at step: 2647 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4257502838426845 at step: 2648 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4257364107678199 at step: 2649 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4257225477144453 at step: 2650 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425708694673464 at step: 2651 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4256948516357901 at step: 2652 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425681018592345 at step: 2653 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4256671955340585 at step: 2654 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4256533824518698 at step: 2655 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4256395793367251 at step: 2656 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4256257861795798 at step: 2657 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4256120029713988 at step: 2658 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4255982297031546 at step: 2659 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4255844663658266 at step: 2660 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425570712950405 at step: 2661 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4255569694478878 at step: 2662 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425543235849281 at step: 2663 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425529512145599 at step: 2664 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4255157983278652 at step: 2665 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425502094387111 at step: 2666 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4254884003143757 at step: 2667 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4254747161007082 at step: 2668 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425461041737165 at step: 2669 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425447377214811 at step: 2670 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.42543372252472 at step: 2671 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4254200776579737 at step: 2672 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425406442605663 at step: 2673 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4253928173588857 at step: 2674 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4253792019087483 at step: 2675 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425365596246368 at step: 2676 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4253520003628668 at step: 2677 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4253384142493783 at step: 2678 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4253248378970422 at step: 2679 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4253112712970066 at step: 2680 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4252977144404297 at step: 2681 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4252841673184764 at step: 2682 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4252706299223208 at step: 2683 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425257102243145 at step: 2684 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4252435842721394 at step: 2685 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4252300760005026 at step: 2686 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4252165774194423 at step: 2687 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4252030885201727 at step: 2688 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4251896092939191 at step: 2689 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4251761397319123 at step: 2690 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4251626798253922 at step: 2691 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425149229565609 at step: 2692 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4251357889438185 at step: 2693 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4251223579512853 at step: 2694 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425108936579284 at step: 2695 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4250955248190957 at step: 2696 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4250821226620105 at step: 2697 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425068730099325 at step: 2698 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4250553471223473 at step: 2699 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.425041973722392 at step: 2700 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4250286098907814 at step: 2701 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4250152556188462 at step: 2702 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4250019108979262 at step: 2703 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424988575719369 at step: 2704 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4249752500745303 at step: 2705 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424961933954774 at step: 2706 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4249486273514729 at step: 2707 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424935330256006 at step: 2708 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4249220426597626 at step: 2709 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4249087645541396 at step: 2710 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4248954959305413 at step: 2711 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4248822367803813 at step: 2712 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4248689870950808 at step: 2713 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424855746866069 at step: 2714 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4248425160847835 at step: 2715 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4248292947426702 at step: 2716 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4248160828311824 at step: 2717 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4248028803417832 at step: 2718 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4247896872659414 at step: 2719 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4247765035951359 at step: 2720 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4247633293208537 at step: 2721 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424750164434588 at step: 2722 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4247370089278426 at step: 2723 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4247238627921273 at step: 2724 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424710726018962 at step: 2725 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4246975985998722 at step: 2726 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4246844805263936 at step: 2727 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4246713717900703 at step: 2728 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4246582723824517 at step: 2729 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4246451822950983 at step: 2730 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424632101519577 at step: 2731 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4246190300474635 at step: 2732 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4246059678703407 at step: 2733 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4245929149798005 at step: 2734 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4245798713674418 at step: 2735 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4245668370248727 at step: 2736 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4245538119437091 at step: 2737 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4245407961155738 at step: 2738 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4245277895320991 at step: 2739 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424514792184924 at step: 2740 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4245018040656974 at step: 2741 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4244888251660743 at step: 2742 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4244758554777177 at step: 2743 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4244628949923 at step: 2744 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4244499437015006 at step: 2745 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4244370015970071 at step: 2746 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424424068670516 at step: 2747 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.42441114491373 at step: 2748 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4243982303183604 at step: 2749 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4243853248761278 at step: 2750 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4243724285787587 at step: 2751 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4243595414179882 at step: 2752 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4243466633855608 at step: 2753 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4243337944732273 at step: 2754 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4243209346727475 at step: 2755 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424308083975887 at step: 2756 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4242952423744222 at step: 2757 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4242824098601352 at step: 2758 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4242695864248178 at step: 2759 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4242567720602684 at step: 2760 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4242439667582933 at step: 2761 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424231170510708 at step: 2762 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4242183833093338 at step: 2763 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4242056051460015 at step: 2764 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.42419283601255 at step: 2765 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4241800759008238 at step: 2766 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4241673248026785 at step: 2767 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4241545827099746 at step: 2768 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424141849614583 at step: 2769 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4241291255083794 at step: 2770 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4241164103832515 at step: 2771 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4241037042310905 at step: 2772 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424091007043797 at step: 2773 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4240783188132824 at step: 2774 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4240656395314604 at step: 2775 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.424052969190257 at step: 2776 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4240403077816048 at step: 2777 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4240276552974422 at step: 2778 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4240150117297186 at step: 2779 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4240023770703882 at step: 2780 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4239897513114153 at step: 2781 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4239771344447703 at step: 2782 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423964526462433 at step: 2783 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4239519273563896 at step: 2784 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4239393371186344 at step: 2785 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4239267557411694 at step: 2786 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423914183216005 at step: 2787 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4239016195351588 at step: 2788 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4238890646906552 at step: 2789 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4238765186745286 at step: 2790 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4238639814788194 at step: 2791 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4238514530955755 at step: 2792 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4238389335168542 at step: 2793 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4238264227347186 at step: 2794 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4238139207412406 at step: 2795 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423801427528499 at step: 2796 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423788943088582 at step: 2797 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4237764674135829 at step: 2798 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4237640004956051 at step: 2799 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4237515423267586 at step: 2800 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4237390928991598 at step: 2801 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4237266522049352 at step: 2802 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423714220236218 at step: 2803 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423701796985148 at step: 2804 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4236893824438739 at step: 2805 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4236769766045516 at step: 2806 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4236645794593439 at step: 2807 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4236521910004227 at step: 2808 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4236398112199664 at step: 2809 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4236274401101618 at step: 2810 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4236150776632022 at step: 2811 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4236027238712894 at step: 2812 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4235903787266326 at step: 2813 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4235780422214488 at step: 2814 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4235657143479614 at step: 2815 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4235533950984027 at step: 2816 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4235410844650125 at step: 2817 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4235287824400378 at step: 2818 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4235164890157324 at step: 2819 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4235042041843586 at step: 2820 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4234919279381866 at step: 2821 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423479660269493 at step: 2822 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4234674011705615 at step: 2823 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4234551506336863 at step: 2824 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4234429086511662 at step: 2825 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4234306752153085 at step: 2826 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423418450318427 at step: 2827 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4234062339528455 at step: 2828 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4233940261108924 at step: 2829 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4233818267849054 at step: 2830 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4233696359672294 at step: 2831 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423357453650216 at step: 2832 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4233452798262256 at step: 2833 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4233331144876242 at step: 2834 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4233209576267873 at step: 2835 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4233088092360962 at step: 2836 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4232966693079407 at step: 2837 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4232845378347183 at step: 2838 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4232724148088323 at step: 2839 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4232603002226938 at step: 2840 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4232481940687232 at step: 2841 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423236096339347 at step: 2842 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4232240070269984 at step: 2843 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4232119261241196 at step: 2844 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423199853623159 at step: 2845 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423187789516572 at step: 2846 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4231757337968232 at step: 2847 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423163686456383 at step: 2848 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4231516474877295 at step: 2849 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4231396168833483 at step: 2850 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4231275946357334 at step: 2851 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423115580737384 at step: 2852 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4231035751808085 at step: 2853 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423091577958521 at step: 2854 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423079589063045 at step: 2855 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4230676084869092 at step: 2856 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4230556362226516 at step: 2857 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4230436722628155 at step: 2858 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.423031716599953 at step: 2859 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4230197692266235 at step: 2860 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4230078301353926 at step: 2861 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4229958993188343 at step: 2862 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4229839767695285 at step: 2863 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4229720624800641 at step: 2864 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4229601564430365 at step: 2865 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4229482586510482 at step: 2866 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4229363690967092 at step: 2867 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422924487772636 at step: 2868 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422912614671454 at step: 2869 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422900749785794 at step: 2870 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422888893108295 at step: 2871 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4228770446316041 at step: 2872 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4228652043483734 at step: 2873 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422853372251264 at step: 2874 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4228415483329433 at step: 2875 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4228297325860866 at step: 2876 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4228179250033763 at step: 2877 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4228061255775013 at step: 2878 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4227943343011586 at step: 2879 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4227825511670509 at step: 2880 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422770776167891 at step: 2881 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422759009296395 at step: 2882 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4227472505452896 at step: 2883 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422735499907306 at step: 2884 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4227237573751847 at step: 2885 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4227120229416725 at step: 2886 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4227002965995221 at step: 2887 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4226885783414958 at step: 2888 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4226768681603608 at step: 2889 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422665166048893 at step: 2890 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4226534719998731 at step: 2891 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4226417860060931 at step: 2892 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4226301080603474 at step: 2893 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4226184381554405 at step: 2894 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4226067762841839 at step: 2895 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4225951224393936 at step: 2896 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4225834766138965 at step: 2897 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4225718388005233 at step: 2898 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4225602089921137 at step: 2899 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4225485871815127 at step: 2900 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4225369733615743 at step: 2901 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4225253675251592 at step: 2902 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422513769665133 at step: 2903 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4225021797743715 at step: 2904 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4224905978457556 at step: 2905 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4224790238721736 at step: 2906 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4224674578465202 at step: 2907 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4224558997616987 at step: 2908 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422444349610618 at step: 2909 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4224328073861945 at step: 2910 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4224212730813517 at step: 2911 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4224097466890204 at step: 2912 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4223982282021372 at step: 2913 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4223867176136455 at step: 2914 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4223752149164983 at step: 2915 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4223637201036532 at step: 2916 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422352233168075 at step: 2917 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4223407541027364 at step: 2918 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4223292829006164 at step: 2919 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4223178195547006 at step: 2920 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422306364057982 at step: 2921 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422294916403461 at step: 2922 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4222834765841441 at step: 2923 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4222720445930448 at step: 2924 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4222606204231838 at step: 2925 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4222492040675887 at step: 2926 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4222377955192937 at step: 2927 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422226394771341 at step: 2928 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4222150018167778 at step: 2929 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4222036166486591 at step: 2930 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221922392600477 at step: 2931 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221808696440115 at step: 2932 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221695077936272 at step: 2933 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221581537019763 at step: 2934 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221468073621482 at step: 2935 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221354687672396 at step: 2936 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221241379103535 at step: 2937 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221128147845992 at step: 2938 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4221014993830938 at step: 2939 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422090191698962 at step: 2940 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4220788917253313 at step: 2941 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4220675994553413 at step: 2942 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4220563148821348 at step: 2943 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.422045037998863 at step: 2944 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4220337687986828 at step: 2945 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4220225072747588 at step: 2946 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4220112534202622 at step: 2947 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4220000072283705 at step: 2948 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4219887686922688 at step: 2949 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4219775378051474 at step: 2950 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4219663145602053 at step: 2951 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421955098950647 at step: 2952 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4219438909696844 at step: 2953 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4219326906105358 at step: 2954 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4219214978664259 at step: 2955 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421910312730586 at step: 2956 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4218991351962544 at step: 2957 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421887965256678 at step: 2958 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4218768029051072 at step: 2959 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4218656481348009 at step: 2960 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4218545009390242 at step: 2961 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421843361311049 at step: 2962 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4218322292441545 at step: 2963 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4218211047316252 at step: 2964 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4218099877667538 at step: 2965 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421798878342838 at step: 2966 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4217877764531834 at step: 2967 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4217766820911026 at step: 2968 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421765595249913 at step: 2969 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4217545159229403 at step: 2970 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4217434441035168 at step: 2971 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4217323797849808 at step: 2972 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4217213229606762 at step: 2973 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4217102736239557 at step: 2974 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421699231768177 at step: 2975 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4216881973867062 at step: 2976 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4216771704729125 at step: 2977 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421666151020176 at step: 2978 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4216551390218801 at step: 2979 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421644134471417 at step: 2980 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4216331373621833 at step: 2981 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4216221476875843 at step: 2982 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4216111654410304 at step: 2983 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421600190615939 at step: 2984 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421589223205734 at step: 2985 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4215782632038463 at step: 2986 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4215673106037126 at step: 2987 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4215563653987764 at step: 2988 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4215454275824884 at step: 2989 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4215344971483042 at step: 2990 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4215235740896877 at step: 2991 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421512658400108 at step: 2992 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4215017500730422 at step: 2993 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214908491019709 at step: 2994 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214799554803856 at step: 2995 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214690692017808 at step: 2996 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214581902596577 at step: 2997 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214473186475254 at step: 2998 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214364543588993 at step: 2999 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214255973873002 at step: 3000 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214147477262566 at step: 3001 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4214039053693024 at step: 3002 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4213930703099777 at step: 3003 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4213822425418317 at step: 3004 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4213714220584157 at step: 3005 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4213606088532906 at step: 3006 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4213498029200227 at step: 3007 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4213390042521854 at step: 3008 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421328212843358 at step: 3009 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4213174286871244 at step: 3010 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4213066517770787 at step: 3011 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4212958821068182 at step: 3012 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4212851196699476 at step: 3013 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4212743644600787 at step: 3014 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4212636164708286 at step: 3015 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4212528756958211 at step: 3016 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4212421421286867 at step: 3017 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4212314157630617 at step: 3018 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421220696592589 at step: 3019 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4212099846109179 at step: 3020 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4211992798117046 at step: 3021 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4211885821886092 at step: 3022 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4211778917353022 at step: 3023 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421167208445456 at step: 3024 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4211565323127533 at step: 3025 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4211458633308798 at step: 3026 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.42113520149353 at step: 3027 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4211245467944023 at step: 3028 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4211138992272039 at step: 3029 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4211032587856463 at step: 3030 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4210926254634484 at step: 3031 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4210819992543353 at step: 3032 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421071380152037 at step: 3033 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.421060768150292 at step: 3034 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4210501632428436 at step: 3035 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4210395654234407 at step: 3036 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4210289746858402 at step: 3037 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4210183910238041 at step: 3038 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4210078144311002 at step: 3039 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4209972449015051 at step: 3040 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4209866824287978 at step: 3041 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4209761270067656 at step: 3042 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420965578629203 at step: 3043 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4209550372899087 at step: 3044 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4209445029826875 at step: 3045 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420933975701353 at step: 3046 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4209234554397216 at step: 3047 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420912942191619 at step: 3048 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4209024359508748 at step: 3049 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420891936711326 at step: 3050 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4208814444668145 at step: 3051 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420870959211189 at step: 3052 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4208604809383059 at step: 3053 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420850009642025 at step: 3054 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420839545316214 at step: 3055 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4208290879547458 at step: 3056 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4208186375515006 at step: 3057 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4208081941003636 at step: 3058 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4207977575952262 at step: 3059 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4207873280299865 at step: 3060 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4207769053985488 at step: 3061 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4207664896948224 at step: 3062 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420756080912723 at step: 3063 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420745679046174 at step: 3064 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4207352840891025 at step: 3065 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4207248960354433 at step: 3066 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420714514879137 at step: 3067 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4207041406141285 at step: 3068 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4206937732343714 at step: 3069 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420683412733824 at step: 3070 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4206730591064507 at step: 3071 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4206627123462225 at step: 3072 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4206523724471152 at step: 3073 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4206420394031114 at step: 3074 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4206317132082 at step: 3075 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420621393856376 at step: 3076 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4206110813416388 at step: 3077 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4206007756579955 at step: 3078 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4205904767994593 at step: 3079 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4205801847600477 at step: 3080 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4205698995337857 at step: 3081 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4205596211147038 at step: 3082 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420549349496839 at step: 3083 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4205390846742323 at step: 3084 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4205288266409337 at step: 3085 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4205185753909964 at step: 3086 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4205083309184807 at step: 3087 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4204980932174534 at step: 3088 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4204878622819863 at step: 3089 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4204776381061568 at step: 3090 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.42046742068405 at step: 3091 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4204572100097552 at step: 3092 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4204470060773684 at step: 3093 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4204368088809913 at step: 3094 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4204266184147307 at step: 3095 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420416434672701 at step: 3096 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4204062576490213 at step: 3097 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420396087337817 at step: 3098 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4203859237332188 at step: 3099 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4203757668293637 at step: 3100 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4203656166203953 at step: 3101 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420355473100461 at step: 3102 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4203453362637162 at step: 3103 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4203352061043217 at step: 3104 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4203250826164426 at step: 3105 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420314965794252 at step: 3106 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420304855631927 at step: 3107 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420294752123652 at step: 3108 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420284655263616 at step: 3109 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4202745650460142 at step: 3110 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4202644814650482 at step: 3111 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4202544045149257 at step: 3112 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4202443341898576 at step: 3113 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4202342704840636 at step: 3114 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420224213391768 at step: 3115 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4202141629072 at step: 3116 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4202041190245969 at step: 3117 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201940817381988 at step: 3118 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201840510422543 at step: 3119 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201740269310161 at step: 3120 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201640093987427 at step: 3121 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201539984396998 at step: 3122 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201439940481562 at step: 3123 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420133996218389 at step: 3124 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201240049446797 at step: 3125 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201140202213163 at step: 3126 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4201040420425914 at step: 3127 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4200940704028047 at step: 3128 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4200841052962596 at step: 3129 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420074146717268 at step: 3130 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420064194660145 at step: 3131 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4200542491192127 at step: 3132 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420044310088798 at step: 3133 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4200343775632347 at step: 3134 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4200244515368614 at step: 3135 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4200145320040218 at step: 3136 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.420004618959067 at step: 3137 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419994712396352 at step: 3138 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199848123102385 at step: 3139 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199749186950938 at step: 3140 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199650315452899 at step: 3141 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199551508552055 at step: 3142 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199452766192244 at step: 3143 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199354088317364 at step: 3144 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199255474871362 at step: 3145 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199156925798244 at step: 3146 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4199058441042083 at step: 3147 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198960020546991 at step: 3148 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198861664257143 at step: 3149 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198763372116776 at step: 3150 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198665144070168 at step: 3151 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419856698006167 at step: 3152 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198468880035684 at step: 3153 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198370843936647 at step: 3154 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198272871709088 at step: 3155 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198174963297558 at step: 3156 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4198077118646686 at step: 3157 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419797933770115 at step: 3158 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4197881620405668 at step: 3159 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4197783966705046 at step: 3160 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419768637654411 at step: 3161 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4197588849867766 at step: 3162 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419749138662096 at step: 3163 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4197393986748708 at step: 3164 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419729665019606 at step: 3165 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4197199376908147 at step: 3166 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4197102166830136 at step: 3167 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419700501990725 at step: 3168 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4196907936084777 at step: 3169 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419681091530805 at step: 3170 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4196713957522458 at step: 3171 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4196617062673453 at step: 3172 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4196520230706535 at step: 3173 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4196423461567256 at step: 3174 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419632675520123 at step: 3175 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419623011155412 at step: 3176 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4196133530571637 at step: 3177 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4196037012199563 at step: 3178 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4195940556383717 at step: 3179 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4195844163069995 at step: 3180 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4195747832204313 at step: 3181 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4195651563732672 at step: 3182 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419555535760112 at step: 3183 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4195459213755743 at step: 3184 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4195363132142693 at step: 3185 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419526711270819 at step: 3186 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419517115539848 at step: 3187 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4195075260159875 at step: 3188 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194979426938747 at step: 3189 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194883655681518 at step: 3190 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194787946334655 at step: 3191 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419469229884469 at step: 3192 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194596713158205 at step: 3193 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194501189221835 at step: 3194 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419440572698226 at step: 3195 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194310326386232 at step: 3196 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194214987380538 at step: 3197 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194119709912028 at step: 3198 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4194024493927604 at step: 3199 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193929339374216 at step: 3200 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193834246198878 at step: 3201 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193739214348644 at step: 3202 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193644243770627 at step: 3203 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193549334411995 at step: 3204 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419345448621997 at step: 3205 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193359699141819 at step: 3206 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193264973124866 at step: 3207 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193170308116492 at step: 3208 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4193075704064122 at step: 3209 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192981160915243 at step: 3210 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192886678617387 at step: 3211 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192792257118139 at step: 3212 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192697896365143 at step: 3213 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192603596306093 at step: 3214 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192509356888723 at step: 3215 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192415178060842 at step: 3216 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419232105977029 at step: 3217 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192227001964972 at step: 3218 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192133004592846 at step: 3219 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4192039067601907 at step: 3220 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191945190940216 at step: 3221 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191851374555886 at step: 3222 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191757618397076 at step: 3223 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191663922411997 at step: 3224 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191570286548916 at step: 3225 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191476710756148 at step: 3226 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419138319498206 at step: 3227 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191289739175075 at step: 3228 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191196343283663 at step: 3229 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419110300725635 at step: 3230 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4191009731041704 at step: 3231 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419091651458835 at step: 3232 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4190823357844973 at step: 3233 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4190730260760298 at step: 3234 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41906372232831 at step: 3235 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419054424536222 at step: 3236 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4190451326946534 at step: 3237 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4190358467984971 at step: 3238 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.419026566842652 at step: 3239 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4190172928220224 at step: 3240 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4190080247315155 at step: 3241 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418998762566046 at step: 3242 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4189895063205322 at step: 3243 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4189802559898983 at step: 3244 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418971011569073 at step: 3245 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4189617730529906 at step: 3246 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4189525404365897 at step: 3247 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418943313714815 at step: 3248 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4189340928826155 at step: 3249 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4189248779349455 at step: 3250 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4189156688667643 at step: 3251 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4189064656730361 at step: 3252 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4188972683487304 at step: 3253 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4188880768888217 at step: 3254 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4188788912882888 at step: 3255 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418869711542117 at step: 3256 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418860537645295 at step: 3257 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4188513695928175 at step: 3258 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4188422073796845 at step: 3259 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4188330510008997 at step: 3260 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418823900451473 at step: 3261 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4188147557264184 at step: 3262 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4188056168207566 at step: 3263 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41879648372951 at step: 3264 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4187873564477091 at step: 3265 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418778234970389 at step: 3266 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418769119292587 at step: 3267 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418760009409349 at step: 3268 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4187509053157237 at step: 3269 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4187418070067648 at step: 3270 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4187327144775324 at step: 3271 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4187236277230895 at step: 3272 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4187145467385058 at step: 3273 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4187054715188547 at step: 3274 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418696402059215 at step: 3275 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186873383546708 at step: 3276 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186782804003104 at step: 3277 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186692281912279 at step: 3278 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186601817225206 at step: 3279 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186511409892932 at step: 3280 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186421059866523 at step: 3281 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186330767097126 at step: 3282 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186240531535916 at step: 3283 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4186150353134115 at step: 3284 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418606023184301 at step: 3285 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418597016761392 at step: 3286 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418588016039822 at step: 3287 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4185790210147338 at step: 3288 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418570031681274 at step: 3289 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418561048034595 at step: 3290 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4185520700698533 at step: 3291 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4185430977822109 at step: 3292 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4185341311668342 at step: 3293 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4185251702188943 at step: 3294 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418516214933568 at step: 3295 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4185072653060362 at step: 3296 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184983213314837 at step: 3297 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184893830051015 at step: 3298 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184804503220856 at step: 3299 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184715232776361 at step: 3300 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184626018669575 at step: 3301 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184536860852597 at step: 3302 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184447759277574 at step: 3303 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184358713896699 at step: 3304 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418426972466221 at step: 3305 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184180791526393 at step: 3306 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184091914441594 at step: 3307 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4184003093360191 at step: 3308 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418391432823462 at step: 3309 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418382561901735 at step: 3310 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418373696566091 at step: 3311 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4183648368117878 at step: 3312 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4183559826340868 at step: 3313 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4183471340282563 at step: 3314 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4183382909895657 at step: 3315 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418329453513293 at step: 3316 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418320621594718 at step: 3317 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418311795229127 at step: 3318 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41830297441181 at step: 3319 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182941591380622 at step: 3320 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182853494031835 at step: 3321 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182765452024781 at step: 3322 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182677465312552 at step: 3323 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182589533848284 at step: 3324 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182501657585163 at step: 3325 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182413836476422 at step: 3326 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182326070475342 at step: 3327 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182238359535242 at step: 3328 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182150703609493 at step: 3329 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4182063102651505 at step: 3330 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4181975556614759 at step: 3331 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418188806545276 at step: 3332 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4181800629119055 at step: 3333 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418171324756726 at step: 3334 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418162592075101 at step: 3335 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4181538648624017 at step: 3336 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418145143114001 at step: 3337 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4181364268252774 at step: 3338 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4181277159916155 at step: 3339 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418119010608403 at step: 3340 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418110310671031 at step: 3341 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4181016161748992 at step: 3342 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4180929271154072 at step: 3343 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4180842434879621 at step: 3344 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418075565287975 at step: 3345 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4180668925108608 at step: 3346 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41805822515204 at step: 3347 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4180495632069368 at step: 3348 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418040906670981 at step: 3349 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4180322555396052 at step: 3350 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4180236098082493 at step: 3351 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4180149694723547 at step: 3352 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.418006334527369 at step: 3353 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4179977049687444 at step: 3354 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417989080791937 at step: 3355 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4179804619924077 at step: 3356 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4179718485656228 at step: 3357 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4179632405070508 at step: 3358 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417954637812167 at step: 3359 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4179460404764501 at step: 3360 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417937448495384 at step: 3361 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417928861864456 at step: 3362 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4179202805791593 at step: 3363 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41791170463499 at step: 3364 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4179031340274506 at step: 3365 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4178945687520461 at step: 3366 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4178860088042868 at step: 3367 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4178774541796881 at step: 3368 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4178689048737696 at step: 3369 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4178603608820537 at step: 3370 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4178518222000696 at step: 3371 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4178432888233496 at step: 3372 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417834760747431 at step: 3373 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417826237967856 at step: 3374 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417817720480169 at step: 3375 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4178092082799212 at step: 3376 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417800701362668 at step: 3377 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177921997239677 at step: 3378 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177837033593848 at step: 3379 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177752122644867 at step: 3380 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177667264348461 at step: 3381 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41775824586604 at step: 3382 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177497705536495 at step: 3383 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177413004932604 at step: 3384 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177328356804624 at step: 3385 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177243761108507 at step: 3386 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177159217800237 at step: 3387 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4177074726835843 at step: 3388 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4176990288171405 at step: 3389 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4176905901763042 at step: 3390 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4176821567566913 at step: 3391 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417673728553923 at step: 3392 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4176653055636237 at step: 3393 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417656887781423 at step: 3394 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4176484752029548 at step: 3395 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4176400678238568 at step: 3396 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417631665639772 at step: 3397 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4176232686463461 at step: 3398 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417614876839231 at step: 3399 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4176064902140812 at step: 3400 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417598108766557 at step: 3401 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175897324923223 at step: 3402 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175813613870447 at step: 3403 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175729954463976 at step: 3404 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175646346660573 at step: 3405 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175562790417051 at step: 3406 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417547928569027 at step: 3407 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175395832437119 at step: 3408 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417531243061454 at step: 3409 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175229080179517 at step: 3410 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175145781089076 at step: 3411 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4175062533300284 at step: 3412 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174979336770253 at step: 3413 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174896191456137 at step: 3414 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174813097315129 at step: 3415 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417473005430446 at step: 3416 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174647062381427 at step: 3417 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174564121503344 at step: 3418 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174481231627578 at step: 3419 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174398392711534 at step: 3420 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174315604712664 at step: 3421 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174232867588459 at step: 3422 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174150181296454 at step: 3423 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4174067545794227 at step: 3424 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4173984961039394 at step: 3425 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4173902426989617 at step: 3426 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41738199436026 at step: 3427 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417373751083608 at step: 3428 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4173655128647855 at step: 3429 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417357279699574 at step: 3430 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4173490515837615 at step: 3431 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4173408285131386 at step: 3432 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417332610483501 at step: 3433 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4173243974906486 at step: 3434 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4173161895303839 at step: 3435 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4173079865985154 at step: 3436 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172997886908552 at step: 3437 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172915958032193 at step: 3438 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417283407931428 at step: 3439 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417275225071305 at step: 3440 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172670472186806 at step: 3441 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172588743693855 at step: 3442 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417250706519258 at step: 3443 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172425436641383 at step: 3444 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172343857998713 at step: 3445 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172262329223067 at step: 3446 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172180850272977 at step: 3447 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172099421107016 at step: 3448 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4172018041683796 at step: 3449 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4171936711961977 at step: 3450 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417185543190025 at step: 3451 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4171774201457354 at step: 3452 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4171693020592078 at step: 3453 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4171611889263231 at step: 3454 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417153080742967 at step: 3455 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4171449775050307 at step: 3456 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4171368792084076 at step: 3457 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4171287858489958 at step: 3458 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417120697422698 at step: 3459 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4171126139254206 at step: 3460 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417104535353073 at step: 3461 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170964617015707 at step: 3462 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417088392966832 at step: 3463 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170803291447784 at step: 3464 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170722702313374 at step: 3465 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170642162224396 at step: 3466 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170561671140192 at step: 3467 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170481229020147 at step: 3468 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170400835823689 at step: 3469 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417032049151028 at step: 3470 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170240196039439 at step: 3471 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4170159949370698 at step: 3472 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.417007975146365 at step: 3473 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169999602277916 at step: 3474 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416991950177317 at step: 3475 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169839449909112 at step: 3476 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416975944664549 at step: 3477 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169679491942089 at step: 3478 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169599585758732 at step: 3479 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169519728055289 at step: 3480 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169439918791658 at step: 3481 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169360157927788 at step: 3482 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169280445423664 at step: 3483 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169200781239308 at step: 3484 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169121165334777 at step: 3485 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4169041597670184 at step: 3486 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168962078205656 at step: 3487 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168882606901394 at step: 3488 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168803183717595 at step: 3489 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416872380861454 at step: 3490 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168644481552513 at step: 3491 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168565202491852 at step: 3492 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168485971392946 at step: 3493 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168406788216201 at step: 3494 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168327652922073 at step: 3495 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416824856547106 at step: 3496 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168169525823695 at step: 3497 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168090533940545 at step: 3498 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4168011589782226 at step: 3499 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167932693309386 at step: 3500 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167853844482712 at step: 3501 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167775043262938 at step: 3502 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167696289610823 at step: 3503 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167617583487173 at step: 3504 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167538924852834 at step: 3505 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167460313668687 at step: 3506 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167381749895658 at step: 3507 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167303233494692 at step: 3508 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167224764426805 at step: 3509 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167146342653016 at step: 3510 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4167067968134408 at step: 3511 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166989640832095 at step: 3512 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166911360707226 at step: 3513 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166833127720986 at step: 3514 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166754941834614 at step: 3515 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166676803009368 at step: 3516 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166598711206546 at step: 3517 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166520666387508 at step: 3518 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166442668513615 at step: 3519 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166364717546294 at step: 3520 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166286813447004 at step: 3521 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166208956177238 at step: 3522 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166131145698522 at step: 3523 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4166053381972428 at step: 3524 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416597566496057 at step: 3525 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165897994624594 at step: 3526 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165820370926168 at step: 3527 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165742793827032 at step: 3528 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165665263288936 at step: 3529 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165587779273676 at step: 3530 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165510341743086 at step: 3531 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165432950659036 at step: 3532 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165355605983438 at step: 3533 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165278307678237 at step: 3534 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165201055705423 at step: 3535 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4165123850027004 at step: 3536 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416504669060505 at step: 3537 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164969577401654 at step: 3538 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164892510378946 at step: 3539 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164815489499103 at step: 3540 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164738514724324 at step: 3541 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164661586016858 at step: 3542 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416458470333899 at step: 3543 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164507866653036 at step: 3544 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164431075921349 at step: 3545 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164354331106328 at step: 3546 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41642776321704 at step: 3547 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416420097907603 at step: 3548 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164124371785718 at step: 3549 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4164047810262015 at step: 3550 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163971294467492 at step: 3551 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163894824364764 at step: 3552 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163818399916484 at step: 3553 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416374202108533 at step: 3554 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416366568783404 at step: 3555 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163589400125365 at step: 3556 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163513157922105 at step: 3557 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163436961187097 at step: 3558 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163360809883208 at step: 3559 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416328470397334 at step: 3560 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163208643420444 at step: 3561 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163132628187496 at step: 3562 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4163056658237512 at step: 3563 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162980733533541 at step: 3564 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162904854038678 at step: 3565 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162829019716043 at step: 3566 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162753230528795 at step: 3567 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162677486440134 at step: 3568 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162601787413298 at step: 3569 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162526133411544 at step: 3570 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162450524398185 at step: 3571 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162374960336555 at step: 3572 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162299441190043 at step: 3573 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162223966922052 at step: 3574 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416214853749603 at step: 3575 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4162073152875472 at step: 3576 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161997813023883 at step: 3577 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161922517904832 at step: 3578 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161847267481904 at step: 3579 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161772061718727 at step: 3580 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161696900578966 at step: 3581 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161621784026321 at step: 3582 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416154671202452 at step: 3583 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416147168453734 at step: 3584 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161396701528577 at step: 3585 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161321762962082 at step: 3586 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416124686880172 at step: 3587 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161172019011414 at step: 3588 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41610972135551 at step: 3589 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4161022452396772 at step: 3590 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160947735500433 at step: 3591 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160873062830146 at step: 3592 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160798434349995 at step: 3593 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160723850024097 at step: 3594 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160649309816622 at step: 3595 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160574813691755 at step: 3596 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160500361613728 at step: 3597 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41604259535468 at step: 3598 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416035158945527 at step: 3599 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160277269303467 at step: 3600 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4160202993055768 at step: 3601 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416012876067657 at step: 3602 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.416005457213031 at step: 3603 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159980427381458 at step: 3604 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159906326394522 at step: 3605 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415983226913405 at step: 3606 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159758255564607 at step: 3607 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159684285650813 at step: 3608 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159610359357315 at step: 3609 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159536476648782 at step: 3610 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159462637489935 at step: 3611 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159388841845524 at step: 3612 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159315089680324 at step: 3613 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159241380959164 at step: 3614 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415916771564689 at step: 3615 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415909409370839 at step: 3616 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4159020515108585 at step: 3617 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158946979812426 at step: 3618 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158873487784904 at step: 3619 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158800038991048 at step: 3620 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158726633395908 at step: 3621 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158653270964574 at step: 3622 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415857995166218 at step: 3623 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158506675453881 at step: 3624 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415843344230487 at step: 3625 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158360252180375 at step: 3626 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158287105045655 at step: 3627 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4158214000866012 at step: 3628 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415814093960677 at step: 3629 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415806792123329 at step: 3630 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157994945710974 at step: 3631 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157922013005253 at step: 3632 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157849123081585 at step: 3633 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415777627590547 at step: 3634 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157703471442444 at step: 3635 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157630709658067 at step: 3636 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157557990517942 at step: 3637 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157485313987692 at step: 3638 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157412680032995 at step: 3639 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415734008861954 at step: 3640 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157267539713065 at step: 3641 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157195033279335 at step: 3642 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415712256928415 at step: 3643 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4157050147693342 at step: 3644 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156977768472774 at step: 3645 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156905431588351 at step: 3646 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415683313700599 at step: 3647 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156760884691681 at step: 3648 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41566886746114 at step: 3649 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156616506731186 at step: 3650 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156544381017113 at step: 3651 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156472297435267 at step: 3652 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156400255951787 at step: 3653 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156328256532826 at step: 3654 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156256299144587 at step: 3655 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156184383753303 at step: 3656 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4156112510325223 at step: 3657 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415604067882666 at step: 3658 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415596888922393 at step: 3659 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155897141483398 at step: 3660 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155825435571452 at step: 3661 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155753771454527 at step: 3662 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415568214909907 at step: 3663 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155610568471586 at step: 3664 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155539029538584 at step: 3665 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415546753226663 at step: 3666 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155396076622309 at step: 3667 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155324662572244 at step: 3668 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155253290083087 at step: 3669 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155181959121528 at step: 3670 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415511066965428 at step: 3671 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4155039421648092 at step: 3672 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4154968215069756 at step: 3673 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4154897049886077 at step: 3674 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415482592606391 at step: 3675 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4154754843570134 at step: 3676 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4154683802371657 at step: 3677 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4154612802435422 at step: 3678 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415454184372841 at step: 3679 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4154470926217626 at step: 3680 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415440004987011 at step: 3681 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4154329214652932 at step: 3682 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41542584205332 at step: 3683 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4154187667478046 at step: 3684 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415411695545464 at step: 3685 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415404628443018 at step: 3686 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153975654371904 at step: 3687 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415390506524706 at step: 3688 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153834517022958 at step: 3689 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153764009666918 at step: 3690 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41536935431463 at step: 3691 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153623117428493 at step: 3692 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153552732480914 at step: 3693 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153482388271026 at step: 3694 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153412084766301 at step: 3695 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153341821934262 at step: 3696 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153271599742456 at step: 3697 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415320141815847 at step: 3698 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153131277149895 at step: 3699 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4153061176684392 at step: 3700 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152991116729619 at step: 3701 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415292109725329 at step: 3702 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152851118223138 at step: 3703 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152781179606926 at step: 3704 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152711281372459 at step: 3705 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415264142348756 at step: 3706 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415257160592009 at step: 3707 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415250182863794 at step: 3708 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415243209160904 at step: 3709 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152362394801337 at step: 3710 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152292738182808 at step: 3711 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152223121721483 at step: 3712 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152153545385402 at step: 3713 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152084009142636 at step: 3714 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4152014512961304 at step: 3715 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151945056809536 at step: 3716 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151875640655507 at step: 3717 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151806264467413 at step: 3718 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415173692821349 at step: 3719 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151667631861995 at step: 3720 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151598375381227 at step: 3721 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41515291587395 at step: 3722 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151459981905175 at step: 3723 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151390844846636 at step: 3724 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151321747532295 at step: 3725 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151252689930596 at step: 3726 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151183672010021 at step: 3727 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4151114693739064 at step: 3728 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415104575508628 at step: 3729 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150976856020223 at step: 3730 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150907996509487 at step: 3731 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415083917652271 at step: 3732 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150770396028547 at step: 3733 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150701654995685 at step: 3734 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415063295339284 at step: 3735 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150564291188763 at step: 3736 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150495668352234 at step: 3737 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150427084852055 at step: 3738 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150358540657078 at step: 3739 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150290035736153 at step: 3740 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41502215700582 at step: 3741 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150153143592128 at step: 3742 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.415008475630691 at step: 3743 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4150016408171529 at step: 3744 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149948099155005 at step: 3745 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149879829226384 at step: 3746 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149811598354745 at step: 3747 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149743406509203 at step: 3748 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414967525365888 at step: 3749 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149607139772964 at step: 3750 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149539064820635 at step: 3751 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149471028771126 at step: 3752 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149403031593697 at step: 3753 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149335073257634 at step: 3754 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149267153732246 at step: 3755 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414919927298688 at step: 3756 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149131430990916 at step: 3757 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4149063627713754 at step: 3758 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148995863124822 at step: 3759 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148928137193597 at step: 3760 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414886044988956 at step: 3761 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148792801182235 at step: 3762 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148725191041178 at step: 3763 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148657619435963 at step: 3764 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41485900863362 at step: 3765 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148522591711534 at step: 3766 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148455135531628 at step: 3767 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148387717766178 at step: 3768 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148320338384912 at step: 3769 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148252997357589 at step: 3770 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148185694653985 at step: 3771 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148118430243914 at step: 3772 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4148051204097234 at step: 3773 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41479840161838 at step: 3774 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414791686647351 at step: 3775 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414784975493631 at step: 3776 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147782681542143 at step: 3777 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147715646261 at step: 3778 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41476486490629 at step: 3779 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414758168991789 at step: 3780 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147514768796035 at step: 3781 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147447885667432 at step: 3782 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147381040502234 at step: 3783 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147314233270576 at step: 3784 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414724746394266 at step: 3785 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147180732488698 at step: 3786 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147114038878936 at step: 3787 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4147047383083649 at step: 3788 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146980765073138 at step: 3789 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146914184817727 at step: 3790 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146847642287788 at step: 3791 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146781137453701 at step: 3792 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414671467028588 at step: 3793 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414664824075477 at step: 3794 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146581848830848 at step: 3795 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146515494484615 at step: 3796 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146449177686589 at step: 3797 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146382898407341 at step: 3798 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146316656617444 at step: 3799 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146250452287528 at step: 3800 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4146184285388217 at step: 3801 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414611815589019 at step: 3802 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414605206376415 at step: 3803 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414598600898081 at step: 3804 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145919991510931 at step: 3805 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145854011325296 at step: 3806 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145788068394716 at step: 3807 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145722162690024 at step: 3808 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414565629418209 at step: 3809 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145590462841802 at step: 3810 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145524668640088 at step: 3811 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41454589115479 at step: 3812 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41453931915362 at step: 3813 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145327508576009 at step: 3814 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414526186263835 at step: 3815 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414519625369429 at step: 3816 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145130681714908 at step: 3817 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4145065146671336 at step: 3818 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144999648534693 at step: 3819 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144934187276168 at step: 3820 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144868762866953 at step: 3821 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144803375278274 at step: 3822 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144738024481387 at step: 3823 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414467271044757 at step: 3824 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144607433148126 at step: 3825 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144542192554408 at step: 3826 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414447698863776 at step: 3827 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144411821369574 at step: 3828 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414434669072128 at step: 3829 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144281596664308 at step: 3830 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144216539170142 at step: 3831 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144151518210277 at step: 3832 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144086533756237 at step: 3833 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4144021585779578 at step: 3834 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143956674251883 at step: 3835 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414389179914475 at step: 3836 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143826960429826 at step: 3837 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143762158078768 at step: 3838 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143697392063261 at step: 3839 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414363266235503 at step: 3840 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143567968925808 at step: 3841 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143503311747367 at step: 3842 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143438690791512 at step: 3843 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414337410603006 at step: 3844 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414330955743486 at step: 3845 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414324504497779 at step: 3846 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143180568630753 at step: 3847 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143116128365687 at step: 3848 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4143051724154543 at step: 3849 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142987355969305 at step: 3850 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142923023781988 at step: 3851 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142858727564624 at step: 3852 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142794467289277 at step: 3853 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142730242928048 at step: 3854 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142666054453044 at step: 3855 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142601901836411 at step: 3856 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142537785050315 at step: 3857 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142473704066965 at step: 3858 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142409658858575 at step: 3859 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142345649397392 at step: 3860 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41422816756557 at step: 3861 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142217737605796 at step: 3862 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142153835220008 at step: 3863 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142089968470697 at step: 3864 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4142026137330241 at step: 3865 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141962341771042 at step: 3866 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414189858176554 at step: 3867 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41418348572862 at step: 3868 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141771168305495 at step: 3869 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141707514795945 at step: 3870 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141643896730087 at step: 3871 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141580314080482 at step: 3872 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141516766819724 at step: 3873 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414145325492043 at step: 3874 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141389778355244 at step: 3875 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414132633709683 at step: 3876 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141262931117882 at step: 3877 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414119956039112 at step: 3878 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141136224889301 at step: 3879 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141072924585176 at step: 3880 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4141009659451567 at step: 3881 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140946429461274 at step: 3882 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140883234587163 at step: 3883 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140820074802103 at step: 3884 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140756950078996 at step: 3885 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414069386039077 at step: 3886 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140630805710368 at step: 3887 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414056778601078 at step: 3888 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140504801265004 at step: 3889 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.414044185144607 at step: 3890 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140378936527027 at step: 3891 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140316056480964 at step: 3892 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140253211280978 at step: 3893 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140190400900203 at step: 3894 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140127625311805 at step: 3895 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140064884488948 at step: 3896 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4140002178404854 at step: 3897 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139939507032744 at step: 3898 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139876870345889 at step: 3899 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139814268317559 at step: 3900 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139751700921073 at step: 3901 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139689168129757 at step: 3902 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139626669916974 at step: 3903 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139564206256106 at step: 3904 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139501777120564 at step: 3905 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139439382483783 at step: 3906 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139377022319224 at step: 3907 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139314696600367 at step: 3908 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413925240530072 at step: 3909 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139190148393825 at step: 3910 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413912792585324 at step: 3911 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4139065737652545 at step: 3912 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413900358376536 at step: 3913 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138941464165304 at step: 3914 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138879378826053 at step: 3915 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138817327721276 at step: 3916 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138755310824693 at step: 3917 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138693328110032 at step: 3918 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138631379551057 at step: 3919 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138569465121555 at step: 3920 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138507584795323 at step: 3921 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138445738546201 at step: 3922 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138383926348048 at step: 3923 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138322148174738 at step: 3924 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138260404000191 at step: 3925 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413819869379833 at step: 3926 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138137017543109 at step: 3927 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138075375208516 at step: 3928 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4138013766768556 at step: 3929 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137952192197254 at step: 3930 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137890651468665 at step: 3931 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413782914455687 at step: 3932 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137767671435975 at step: 3933 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137706232080103 at step: 3934 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137644826463407 at step: 3935 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137583454560063 at step: 3936 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137522116344279 at step: 3937 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137460811790266 at step: 3938 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137399540872282 at step: 3939 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137338303564604 at step: 3940 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137277099841519 at step: 3941 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137215929677356 at step: 3942 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413715479304646 at step: 3943 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137093689923206 at step: 3944 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4137032620281977 at step: 3945 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136971584097202 at step: 3946 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136910581343316 at step: 3947 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413684961199479 at step: 3948 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136788676026115 at step: 3949 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136727773411804 at step: 3950 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136666904126396 at step: 3951 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136606068144455 at step: 3952 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136545265440563 at step: 3953 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413648449598933 at step: 3954 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136423759765395 at step: 3955 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136363056743417 at step: 3956 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136302386898068 at step: 3957 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413624175020407 at step: 3958 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413618114663613 at step: 3959 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413612057616902 at step: 3960 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4136060038777511 at step: 3961 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135999534436403 at step: 3962 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135939063120513 at step: 3963 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41358786248047 at step: 3964 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135818219463827 at step: 3965 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135757847072798 at step: 3966 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135697507606522 at step: 3967 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413563720103995 at step: 3968 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135576927348033 at step: 3969 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135516686505771 at step: 3970 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135456478488178 at step: 3971 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135396303270287 at step: 3972 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135336160827154 at step: 3973 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135276051133867 at step: 3974 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135215974165527 at step: 3975 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135155929897265 at step: 3976 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4135095918304235 at step: 3977 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413503593936161 at step: 3978 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134975993044598 at step: 3979 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134916079328403 at step: 3980 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134856198188295 at step: 3981 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134796349599523 at step: 3982 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134736533537389 at step: 3983 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41346767499772 at step: 3984 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134616998894303 at step: 3985 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134557280264055 at step: 3986 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413449759406184 at step: 3987 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134437940263067 at step: 3988 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134378318843166 at step: 3989 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134318729777589 at step: 3990 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413425917304181 at step: 3991 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134199648611339 at step: 3992 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4134140156461688 at step: 3993 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41340806965684 at step: 3994 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413402126890705 at step: 3995 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133961873453231 at step: 3996 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133902510182543 at step: 3997 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133843179070638 at step: 3998 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133783880093167 at step: 3999 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133724613225813 at step: 4000 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413366537844428 at step: 4001 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41336061757243 at step: 4002 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133547005041611 at step: 4003 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133487866371996 at step: 4004 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413342875969125 at step: 4005 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133369684975188 at step: 4006 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133310642199657 at step: 4007 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133251631340504 at step: 4008 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413319265237363 at step: 4009 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133133705274938 at step: 4010 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133074790020355 at step: 4011 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4133015906585842 at step: 4012 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132957054947362 at step: 4013 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132898235080922 at step: 4014 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132839446962542 at step: 4015 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132780690568256 at step: 4016 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132721965874144 at step: 4017 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413266327285628 at step: 4018 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132604611490778 at step: 4019 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132545981753775 at step: 4020 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132487383621408 at step: 4021 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132428817069875 at step: 4022 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132370282075355 at step: 4023 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132311778614082 at step: 4024 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132253306662295 at step: 4025 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132194866196257 at step: 4026 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413213645719225 at step: 4027 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132078079626595 at step: 4028 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4132019733475614 at step: 4029 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131961418715662 at step: 4030 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131903135323112 at step: 4031 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131844883274365 at step: 4032 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413178666254584 at step: 4033 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131728473113974 at step: 4034 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131670314955236 at step: 4035 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41316121880461 at step: 4036 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131554092363083 at step: 4037 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131496027882708 at step: 4038 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131437994581526 at step: 4039 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131379992436113 at step: 4040 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131322021423054 at step: 4041 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131264081518977 at step: 4042 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131206172700508 at step: 4043 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131148294944311 at step: 4044 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131090448227062 at step: 4045 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4131032632525469 at step: 4046 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130974847816256 at step: 4047 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413091709407616 at step: 4048 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130859371281959 at step: 4049 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130801679410439 at step: 4050 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130744018438408 at step: 4051 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130686388342695 at step: 4052 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413062878910016 at step: 4053 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413057122068767 at step: 4054 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130513683082127 at step: 4055 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130456176260444 at step: 4056 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130398700199565 at step: 4057 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413034125487645 at step: 4058 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130283840268079 at step: 4059 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413022645635145 at step: 4060 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130169103103594 at step: 4061 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.413011178050156 at step: 4062 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4130054488522397 at step: 4063 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129997227143223 at step: 4064 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129939996341119 at step: 4065 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129882796093232 at step: 4066 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129825626376704 at step: 4067 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129768487168712 at step: 4068 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129711378446455 at step: 4069 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129654300187147 at step: 4070 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129597252368016 at step: 4071 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129540234966327 at step: 4072 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129483247959351 at step: 4073 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41294262913244 at step: 4074 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129369365038782 at step: 4075 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129312469079842 at step: 4076 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129255603424946 at step: 4077 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129198768051476 at step: 4078 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129141962936829 at step: 4079 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129085188058443 at step: 4080 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4129028443393754 at step: 4081 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128971728920232 at step: 4082 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128915044615364 at step: 4083 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128858390456658 at step: 4084 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128801766421641 at step: 4085 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128745172487878 at step: 4086 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128688608632918 at step: 4087 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128632074834362 at step: 4088 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128575571069826 at step: 4089 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128519097316938 at step: 4090 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128462653553346 at step: 4091 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128406239756734 at step: 4092 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128349855904796 at step: 4093 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128293501975246 at step: 4094 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128237177945808 at step: 4095 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128180883794257 at step: 4096 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412812461949836 at step: 4097 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4128068385035915 at step: 4098 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412801218038474 at step: 4099 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412795600552267 at step: 4100 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127899860427573 at step: 4101 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127843745077318 at step: 4102 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412778765944981 at step: 4103 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127731603522964 at step: 4104 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127675577274728 at step: 4105 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127619580683057 at step: 4106 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412756361372593 at step: 4107 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127507676381352 at step: 4108 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127451768627346 at step: 4109 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127395890441952 at step: 4110 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127340041803227 at step: 4111 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412728422268926 at step: 4112 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127228433078147 at step: 4113 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127172672948016 at step: 4114 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127116942277005 at step: 4115 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412706124104328 at step: 4116 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4127005569225017 at step: 4117 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126949926800425 at step: 4118 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126894313747727 at step: 4119 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412683873004516 at step: 4120 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126783175670998 at step: 4121 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126727650603512 at step: 4122 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126672154821014 at step: 4123 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126616688301816 at step: 4124 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126561251024268 at step: 4125 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412650584296673 at step: 4126 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126450464107585 at step: 4127 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126395114425239 at step: 4128 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126339793898104 at step: 4129 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126284502504638 at step: 4130 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126229240223283 at step: 4131 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412617400703254 at step: 4132 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126118802910894 at step: 4133 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4126063627836873 at step: 4134 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412600848178902 at step: 4135 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125953364745887 at step: 4136 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125898276686066 at step: 4137 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125843217588139 at step: 4138 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125788187430748 at step: 4139 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125733186192513 at step: 4140 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41256782138521 at step: 4141 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125623270388186 at step: 4142 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125568355779472 at step: 4143 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125513470004671 at step: 4144 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125458613042519 at step: 4145 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412540378487177 at step: 4146 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125348985471207 at step: 4147 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412529421481962 at step: 4148 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125239472895825 at step: 4149 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125184759678648 at step: 4150 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125130075146957 at step: 4151 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125075419279614 at step: 4152 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4125020792055514 at step: 4153 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124966193453563 at step: 4154 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124911623452703 at step: 4155 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124857082031872 at step: 4156 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124802569170047 at step: 4157 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124748084846208 at step: 4158 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124693629039369 at step: 4159 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124639201728553 at step: 4160 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412458480289281 at step: 4161 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124530432511202 at step: 4162 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124476090562812 at step: 4163 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124421777026746 at step: 4164 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124367491882128 at step: 4165 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124313235108095 at step: 4166 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124259006683801 at step: 4167 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124204806588447 at step: 4168 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124150634801207 at step: 4169 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124096491301315 at step: 4170 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4124042376068 at step: 4171 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123988289080516 at step: 4172 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412393423031814 at step: 4173 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412388019976017 at step: 4174 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412382619738591 at step: 4175 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41237722231747 at step: 4176 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123718277105881 at step: 4177 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123664359158827 at step: 4178 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123610469312922 at step: 4179 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123556607547578 at step: 4180 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123502773842211 at step: 4181 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412344896817628 at step: 4182 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123395190529229 at step: 4183 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412334144088055 at step: 4184 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123287719209734 at step: 4185 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123234025496318 at step: 4186 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123180359719827 at step: 4187 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412312672185981 at step: 4188 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4123073111895863 at step: 4189 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412301952980756 at step: 4190 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122965975574513 at step: 4191 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122912449176361 at step: 4192 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122858950592752 at step: 4193 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122805479803353 at step: 4194 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122752036787845 at step: 4195 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122698621525938 at step: 4196 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122645233997349 at step: 4197 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122591874181825 at step: 4198 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122538542059124 at step: 4199 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122485237609026 at step: 4200 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122431960811324 at step: 4201 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122378711645833 at step: 4202 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122325490092387 at step: 4203 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122272296130836 at step: 4204 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122219129741054 at step: 4205 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122165990902928 at step: 4206 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122112879596367 at step: 4207 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122059795801287 at step: 4208 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4122006739497632 at step: 4209 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121953710665376 at step: 4210 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121900709284483 at step: 4211 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412184773533496 at step: 4212 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412179478879682 at step: 4213 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121741869650093 at step: 4214 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121688977874838 at step: 4215 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121636113451117 at step: 4216 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121583276359027 at step: 4217 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121530466578665 at step: 4218 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412147768409016 at step: 4219 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412142492887366 at step: 4220 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121372200909315 at step: 4221 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121319500177305 at step: 4222 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121266826657832 at step: 4223 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121214180331108 at step: 4224 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121161561177362 at step: 4225 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121108969176843 at step: 4226 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4121056404309822 at step: 4227 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412100386655659 at step: 4228 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412095135589744 at step: 4229 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120898872312697 at step: 4230 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120846415782702 at step: 4231 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120793986287816 at step: 4232 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120741583808403 at step: 4233 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120689208324866 at step: 4234 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120636859817608 at step: 4235 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120584538267058 at step: 4236 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412053224365367 at step: 4237 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41204799759579 at step: 4238 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120427735160228 at step: 4239 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120375521241155 at step: 4240 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120323334181202 at step: 4241 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120271173960894 at step: 4242 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120219040560786 at step: 4243 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120166933961449 at step: 4244 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120114854143473 at step: 4245 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4120062801087454 at step: 4246 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.412001077477402 at step: 4247 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119958775183805 at step: 4248 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119906802297473 at step: 4249 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119854856095693 at step: 4250 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119802936559158 at step: 4251 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119751043668578 at step: 4252 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119699177404674 at step: 4253 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41196473377482 at step: 4254 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119595524679904 at step: 4255 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119543738180582 at step: 4256 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119491978231011 at step: 4257 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119440244812016 at step: 4258 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119388537904434 at step: 4259 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119336857489098 at step: 4260 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119285203546876 at step: 4261 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119233576058652 at step: 4262 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119181975005333 at step: 4263 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411913040036783 at step: 4264 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119078852127074 at step: 4265 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4119027330264022 at step: 4266 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118975834759637 at step: 4267 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411892436559491 at step: 4268 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411887292275084 at step: 4269 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118821506208448 at step: 4270 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118770115948767 at step: 4271 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411871875195286 at step: 4272 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118667414201789 at step: 4273 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118616102676644 at step: 4274 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118564817358537 at step: 4275 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118513558228576 at step: 4276 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411846232526791 at step: 4277 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41184111184577 at step: 4278 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118359937779101 at step: 4279 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118308783213327 at step: 4280 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118257654741566 at step: 4281 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118206552345043 at step: 4282 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411815547600501 at step: 4283 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118104425702707 at step: 4284 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4118053401419426 at step: 4285 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411800240313645 at step: 4286 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117951430835085 at step: 4287 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117900484496657 at step: 4288 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411784956410251 at step: 4289 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117798669633996 at step: 4290 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117747801072498 at step: 4291 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117696958399406 at step: 4292 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117646141596123 at step: 4293 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117595350644077 at step: 4294 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411754458552471 at step: 4295 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117493846219478 at step: 4296 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117443132709857 at step: 4297 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411739244497734 at step: 4298 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117341783003434 at step: 4299 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117291146769668 at step: 4300 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411724053625757 at step: 4301 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117189951448719 at step: 4302 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117139392324667 at step: 4303 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117088858867022 at step: 4304 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4117038351057378 at step: 4305 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411698786887737 at step: 4306 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411693741230863 at step: 4307 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116886981332821 at step: 4308 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116836575931617 at step: 4309 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41167861960867 at step: 4310 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116735841779777 at step: 4311 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116685512992575 at step: 4312 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411663520970683 at step: 4313 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41165849319043 at step: 4314 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116534679566752 at step: 4315 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411648445267597 at step: 4316 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116434251213774 at step: 4317 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411638407516197 at step: 4318 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41163339245024 at step: 4319 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411628379921691 at step: 4320 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116233699287375 at step: 4321 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411618362469568 at step: 4322 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116133575423724 at step: 4323 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116083551453422 at step: 4324 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4116033552766716 at step: 4325 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115983579345552 at step: 4326 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115933631171889 at step: 4327 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115883708227717 at step: 4328 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411583381049503 at step: 4329 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115783937955848 at step: 4330 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115734090592191 at step: 4331 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115684268386117 at step: 4332 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411563447131968 at step: 4333 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411558469937496 at step: 4334 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115534952534052 at step: 4335 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115485230779066 at step: 4336 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115435534092127 at step: 4337 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411538586245538 at step: 4338 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115336215850978 at step: 4339 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115286594261103 at step: 4340 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115236997667935 at step: 4341 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115187426053681 at step: 4342 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115137879400572 at step: 4343 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4115088357690841 at step: 4344 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411503886090674 at step: 4345 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114989389030528 at step: 4346 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114939942044507 at step: 4347 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114890519930967 at step: 4348 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114841122672226 at step: 4349 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114791750250621 at step: 4350 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114742402648495 at step: 4351 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411469307984821 at step: 4352 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114643781832148 at step: 4353 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41145945085827 at step: 4354 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114545260082285 at step: 4355 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114496036313322 at step: 4356 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114446837258259 at step: 4357 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114397662899543 at step: 4358 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114348513219652 at step: 4359 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114299388201077 at step: 4360 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114250287826322 at step: 4361 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114201212077906 at step: 4362 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114152160938365 at step: 4363 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114103134390243 at step: 4364 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411405413241611 at step: 4365 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4114005154998552 at step: 4366 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113956202120164 at step: 4367 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113907273763557 at step: 4368 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113858369911363 at step: 4369 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113809490546214 at step: 4370 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411376063565078 at step: 4371 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113711805207736 at step: 4372 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113662999199765 at step: 4373 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113614217609576 at step: 4374 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113565460419886 at step: 4375 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113516727613429 at step: 4376 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113468019172966 at step: 4377 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113419335081254 at step: 4378 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411337067532108 at step: 4379 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113322039875231 at step: 4380 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113273428726534 at step: 4381 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113224841857799 at step: 4382 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113176279251882 at step: 4383 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113127740891638 at step: 4384 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113079226759937 at step: 4385 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4113030736839667 at step: 4386 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411298227111373 at step: 4387 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112933829565049 at step: 4388 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112885412176555 at step: 4389 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112837018931192 at step: 4390 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112788649811931 at step: 4391 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112740304801747 at step: 4392 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112691983883634 at step: 4393 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41126436870406 at step: 4394 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411259541425567 at step: 4395 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112547165511877 at step: 4396 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112498940792286 at step: 4397 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411245074007996 at step: 4398 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112402563357975 at step: 4399 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112354410609442 at step: 4400 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112306281817468 at step: 4401 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112258176965182 at step: 4402 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411221009603573 at step: 4403 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411216203901227 at step: 4404 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411211400587797 at step: 4405 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4112065996616023 at step: 4406 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411201801120963 at step: 4407 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111970049642015 at step: 4408 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41119221118964 at step: 4409 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111874197956034 at step: 4410 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111826307804187 at step: 4411 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111778441424128 at step: 4412 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111730598799153 at step: 4413 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111682779912562 at step: 4414 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111634984747687 at step: 4415 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411158721328785 at step: 4416 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111539465516414 at step: 4417 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111491741416737 at step: 4418 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111444040972203 at step: 4419 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111396364166204 at step: 4420 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111348710982141 at step: 4421 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111301081403456 at step: 4422 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111253475413574 at step: 4423 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111205892995944 at step: 4424 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411115833413405 at step: 4425 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111110798811353 at step: 4426 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111063287011367 at step: 4427 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4111015798717594 at step: 4428 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110968333913563 at step: 4429 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110920892582814 at step: 4430 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110873474708894 at step: 4431 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110826080275383 at step: 4432 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110778709265857 at step: 4433 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110731361663917 at step: 4434 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110684037453178 at step: 4435 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110636736617257 at step: 4436 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110589459139808 at step: 4437 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110542205004473 at step: 4438 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110494974194931 at step: 4439 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110447766694867 at step: 4440 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110400582487972 at step: 4441 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110353421557957 at step: 4442 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110306283888563 at step: 4443 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110259169463524 at step: 4444 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110212078266584 at step: 4445 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110165010281528 at step: 4446 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411011796549214 at step: 4447 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.411007094388221 at step: 4448 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4110023945435555 at step: 4449 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109976970136002 at step: 4450 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109930017967387 at step: 4451 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109883088913573 at step: 4452 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109836182958424 at step: 4453 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109789300085822 at step: 4454 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109742440279671 at step: 4455 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109695603523877 at step: 4456 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109648789802365 at step: 4457 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109601999099086 at step: 4458 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410955523139798 at step: 4459 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410950848668302 at step: 4460 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109461764938185 at step: 4461 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109415066147475 at step: 4462 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109368390294903 at step: 4463 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109321737364486 at step: 4464 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109275107340262 at step: 4465 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109228500206297 at step: 4466 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109181915946638 at step: 4467 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109135354545372 at step: 4468 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4109088815986595 at step: 4469 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410904230025441 at step: 4470 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108995807332945 at step: 4471 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108949337206336 at step: 4472 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108902889858723 at step: 4473 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410885646527428 at step: 4474 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108810063437176 at step: 4475 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41087636843316 at step: 4476 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108717327941767 at step: 4477 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108670994251884 at step: 4478 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108624683246196 at step: 4479 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410857839490894 at step: 4480 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108532129224374 at step: 4481 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108485886176776 at step: 4482 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108439665750439 at step: 4483 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108393467929652 at step: 4484 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108347292698735 at step: 4485 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108301140042017 at step: 4486 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410825500994384 at step: 4487 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410820890238856 at step: 4488 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108162817360541 at step: 4489 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108116754844173 at step: 4490 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108070714823848 at step: 4491 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4108024697283983 at step: 4492 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107978702208992 at step: 4493 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410793272958332 at step: 4494 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107886779391412 at step: 4495 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107840851617737 at step: 4496 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107794946246774 at step: 4497 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107749063263004 at step: 4498 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107703202650945 at step: 4499 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107657364395112 at step: 4500 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410761154848003 at step: 4501 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410756575489025 at step: 4502 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107519983610335 at step: 4503 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107474234624848 at step: 4504 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410742850791838 at step: 4505 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410738280347553 at step: 4506 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410733712128091 at step: 4507 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107291461319147 at step: 4508 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107245823574883 at step: 4509 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410720020803276 at step: 4510 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410715461467745 at step: 4511 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107109043493637 at step: 4512 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410706349446601 at step: 4513 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4107017967579272 at step: 4514 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106972462818148 at step: 4515 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106926980167365 at step: 4516 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106881519611671 at step: 4517 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106836081135823 at step: 4518 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41067906647246 at step: 4519 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106745270362775 at step: 4520 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106699898035158 at step: 4521 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410665454772656 at step: 4522 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41066092194218 at step: 4523 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106563913105716 at step: 4524 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106518628763163 at step: 4525 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106473366379009 at step: 4526 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106428125938126 at step: 4527 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106382907425405 at step: 4528 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410633771082575 at step: 4529 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410629253612408 at step: 4530 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106247383305324 at step: 4531 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106202252354423 at step: 4532 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106157143256337 at step: 4533 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410611205599603 at step: 4534 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106066990558492 at step: 4535 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4106021946928702 at step: 4536 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410597692509169 at step: 4537 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105931925032462 at step: 4538 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105886946736055 at step: 4539 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105841990187518 at step: 4540 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105797055371914 at step: 4541 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105752142274308 at step: 4542 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410570725087979 at step: 4543 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410566238117346 at step: 4544 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105617533140424 at step: 4545 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105572706765817 at step: 4546 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105527902034765 at step: 4547 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105483118932423 at step: 4548 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105438357443951 at step: 4549 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105393617554531 at step: 4550 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105348899249353 at step: 4551 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105304202513607 at step: 4552 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105259527332512 at step: 4553 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105214873691305 at step: 4554 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105170241575213 at step: 4555 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410512563096949 at step: 4556 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4105081041859409 at step: 4557 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410503647423024 at step: 4558 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104991928067279 at step: 4559 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104947403355823 at step: 4560 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104902900081193 at step: 4561 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410485841822872 at step: 4562 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104813957783742 at step: 4563 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104769518731612 at step: 4564 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104725101057694 at step: 4565 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104680704747377 at step: 4566 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104636329786042 at step: 4567 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104591976159095 at step: 4568 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104547643851963 at step: 4569 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410450333285006 at step: 4570 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104459043138846 at step: 4571 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104414774703762 at step: 4572 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104370527530277 at step: 4573 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104326301603873 at step: 4574 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104282096910046 at step: 4575 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104237913434292 at step: 4576 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104193751162135 at step: 4577 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104149610079104 at step: 4578 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104105490170737 at step: 4579 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41040613914226 at step: 4580 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4104017313820234 at step: 4581 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103973257349252 at step: 4582 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103929221995222 at step: 4583 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103885207743754 at step: 4584 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103841214580466 at step: 4585 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103797242490985 at step: 4586 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103753291460959 at step: 4587 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410370936147603 at step: 4588 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103665452521876 at step: 4589 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103621564584168 at step: 4590 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103577697648593 at step: 4591 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410353385170086 at step: 4592 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103490026726688 at step: 4593 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103446222711795 at step: 4594 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103402439641926 at step: 4595 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103358677502829 at step: 4596 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103314936280271 at step: 4597 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103271215960032 at step: 4598 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410322751652789 at step: 4599 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103183837969653 at step: 4600 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103140180271134 at step: 4601 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103096543418154 at step: 4602 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103052927396553 at step: 4603 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4103009332192185 at step: 4604 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102965757790902 at step: 4605 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102922204178578 at step: 4606 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102878671341108 at step: 4607 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102835159264386 at step: 4608 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102791667934313 at step: 4609 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102748197336827 at step: 4610 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102704747457846 at step: 4611 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102661318283327 at step: 4612 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102617909799222 at step: 4613 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102574521991498 at step: 4614 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102531154846147 at step: 4615 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102487808349156 at step: 4616 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102444482486534 at step: 4617 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102401177244295 at step: 4618 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102357892608477 at step: 4619 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102314628565114 at step: 4620 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410227138510026 at step: 4621 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102228162199986 at step: 4622 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102184959850366 at step: 4623 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410214177803749 at step: 4624 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102098616747463 at step: 4625 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102055475966386 at step: 4626 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4102012355680402 at step: 4627 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101969255875637 at step: 4628 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410192617653824 at step: 4629 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101883117654377 at step: 4630 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101840079210217 at step: 4631 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410179706119194 at step: 4632 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101754063585754 at step: 4633 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101711086377855 at step: 4634 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101668129554463 at step: 4635 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101625193101823 at step: 4636 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101582277006162 at step: 4637 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101539381253743 at step: 4638 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101496505830835 at step: 4639 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101453650723705 at step: 4640 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101410815918658 at step: 4641 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101368001401986 at step: 4642 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101325207160003 at step: 4643 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101282433179037 at step: 4644 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101239679445425 at step: 4645 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410119694594551 at step: 4646 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101154232665658 at step: 4647 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410111153959224 at step: 4648 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101068866711635 at step: 4649 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4101026214010237 at step: 4650 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100983581474462 at step: 4651 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410094096909072 at step: 4652 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100898376845437 at step: 4653 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410085580472506 at step: 4654 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100813252716042 at step: 4655 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100770720804845 at step: 4656 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100728208977944 at step: 4657 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100685717221828 at step: 4658 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100643245522995 at step: 4659 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410060079386796 at step: 4660 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100558362243227 at step: 4661 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410051595063535 at step: 4662 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100473559030864 at step: 4663 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100431187416322 at step: 4664 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.41003888357783 at step: 4665 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100346504103365 at step: 4666 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100304192378112 at step: 4667 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410026190058915 at step: 4668 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410021962872308 at step: 4669 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100177376766543 at step: 4670 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410013514470615 at step: 4671 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100092932528567 at step: 4672 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.410005074022045 at step: 4673 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4100008567768458 at step: 4674 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099966415159282 at step: 4675 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099924282379612 at step: 4676 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099882169416147 at step: 4677 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099840076255608 at step: 4678 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099798002884716 at step: 4679 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409975594929021 at step: 4680 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099713915458836 at step: 4681 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409967190137736 at step: 4682 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099629907032547 at step: 4683 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099587932411182 at step: 4684 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099545977500056 at step: 4685 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099504042285975 at step: 4686 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099462126755753 at step: 4687 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099420230896222 at step: 4688 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099378354694212 at step: 4689 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099336498136579 at step: 4690 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099294661210175 at step: 4691 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099252843901882 at step: 4692 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099211046198576 at step: 4693 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409916926808715 at step: 4694 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099127509554508 at step: 4695 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099085770587574 at step: 4696 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099044051173262 at step: 4697 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4099002351298515 at step: 4698 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409896067095029 at step: 4699 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098919010115538 at step: 4700 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098877368781226 at step: 4701 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098835746934344 at step: 4702 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098794144561884 at step: 4703 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098752561650847 at step: 4704 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098710998188249 at step: 4705 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098669454161117 at step: 4706 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098627929556482 at step: 4707 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098586424361397 at step: 4708 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409854493856292 at step: 4709 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409850347214812 at step: 4710 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409846202510408 at step: 4711 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098420597417887 at step: 4712 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098379189076644 at step: 4713 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409833780006746 at step: 4714 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098296430377473 at step: 4715 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098255079993804 at step: 4716 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098213748903603 at step: 4717 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098172437094028 at step: 4718 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409813114455224 at step: 4719 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409808987126543 at step: 4720 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4098048617220773 at step: 4721 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409800738240548 at step: 4722 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409796616680675 at step: 4723 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097924970411813 at step: 4724 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097883793207893 at step: 4725 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097842635182243 at step: 4726 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409780149632211 at step: 4727 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409776037661476 at step: 4728 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097719276047467 at step: 4729 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409767819460751 at step: 4730 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097637132282206 at step: 4731 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409759608905884 at step: 4732 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097555064924734 at step: 4733 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097514059867222 at step: 4734 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097473073873643 at step: 4735 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097432106931342 at step: 4736 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097391159027686 at step: 4737 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409735023015004 at step: 4738 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097309320285785 at step: 4739 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097268429422314 at step: 4740 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409722755754703 at step: 4741 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097186704647349 at step: 4742 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409714587071069 at step: 4743 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097105055724493 at step: 4744 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409706425967619 at step: 4745 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4097023482553257 at step: 4746 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096982724343146 at step: 4747 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096941985033336 at step: 4748 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096901264611312 at step: 4749 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096860563064575 at step: 4750 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096819880380633 at step: 4751 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096779216547002 at step: 4752 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409673857155121 at step: 4753 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096697945380796 at step: 4754 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096657338023313 at step: 4755 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096616749466322 at step: 4756 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096576179697389 at step: 4757 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096535628704099 at step: 4758 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409649509647404 at step: 4759 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096454582994822 at step: 4760 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409641408825404 at step: 4761 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096373612239335 at step: 4762 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096333154938328 at step: 4763 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096292716338668 at step: 4764 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096252296428005 at step: 4765 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096211895194004 at step: 4766 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096171512624347 at step: 4767 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096131148706703 at step: 4768 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409609080342878 at step: 4769 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096050476778275 at step: 4770 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4096010168742907 at step: 4771 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095969879310404 at step: 4772 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095929608468496 at step: 4773 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095889356204938 at step: 4774 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095849122507473 at step: 4775 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409580890736388 at step: 4776 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095768710761925 at step: 4777 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095728532689407 at step: 4778 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095688373134116 at step: 4779 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409564823208386 at step: 4780 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409560810952646 at step: 4781 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095568005449741 at step: 4782 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095527919841537 at step: 4783 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095487852689703 at step: 4784 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095447803982093 at step: 4785 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095407773706574 at step: 4786 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095367761851032 at step: 4787 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095327768403345 at step: 4788 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095287793351423 at step: 4789 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095247836683167 at step: 4790 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409520789838649 at step: 4791 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095167978449337 at step: 4792 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095128076859635 at step: 4793 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095088193605334 at step: 4794 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.40950483286744 at step: 4795 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4095008482054796 at step: 4796 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094968653734499 at step: 4797 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094928843701504 at step: 4798 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094889051943809 at step: 4799 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094849278449417 at step: 4800 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094809523206355 at step: 4801 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094769786202648 at step: 4802 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094730067426333 at step: 4803 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094690366865463 at step: 4804 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094650684508097 at step: 4805 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094611020342294 at step: 4806 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094571374356148 at step: 4807 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094531746537733 at step: 4808 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094492136875159 at step: 4809 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094452545356526 at step: 4810 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409441297196996 at step: 4811 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094373416703587 at step: 4812 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094333879545538 at step: 4813 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094294360483972 at step: 4814 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409425485950703 at step: 4815 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094215376602899 at step: 4816 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409417591175974 at step: 4817 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409413646496575 at step: 4818 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4094097036209126 at step: 4819 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409405762547807 at step: 4820 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.40940182327608 at step: 4821 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409397885804554 at step: 4822 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093939501320534 at step: 4823 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093900162574016 at step: 4824 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093860841794252 at step: 4825 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093821538969507 at step: 4826 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093782254088045 at step: 4827 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093742987138163 at step: 4828 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093703738108145 at step: 4829 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093664506986303 at step: 4830 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409362529376095 at step: 4831 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093586098420408 at step: 4832 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093546920953004 at step: 4833 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093507761347095 at step: 4834 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093468619591019 at step: 4835 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093429495673144 at step: 4836 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093390389581841 at step: 4837 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093351301305495 at step: 4838 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409331223083249 at step: 4839 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093273178151233 at step: 4840 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093234143250133 at step: 4841 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093195126117606 at step: 4842 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093156126742088 at step: 4843 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093117145112009 at step: 4844 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093078181215823 at step: 4845 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4093039235041986 at step: 4846 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409300030657897 at step: 4847 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092961395815244 at step: 4848 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092922502739302 at step: 4849 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092883627339636 at step: 4850 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092844769604753 at step: 4851 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092805929523167 at step: 4852 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.40927671070834 at step: 4853 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092728302273991 at step: 4854 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092689515083483 at step: 4855 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092650745500432 at step: 4856 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092611993513386 at step: 4857 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092573259110934 at step: 4858 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092534542281645 at step: 4859 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092495843014115 at step: 4860 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092457161296945 at step: 4861 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092418497118737 at step: 4862 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092379850468126 at step: 4863 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092341221333722 at step: 4864 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092302609704173 at step: 4865 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092264015568123 at step: 4866 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409222543891423 at step: 4867 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092186879731154 at step: 4868 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092148338007573 at step: 4869 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092109813732177 at step: 4870 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092071306893654 at step: 4871 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4092032817480706 at step: 4872 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409199434548205 at step: 4873 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.40919558908864 at step: 4874 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091917453682494 at step: 4875 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091879033859067 at step: 4876 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091840631404875 at step: 4877 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091802246308665 at step: 4878 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091763878559216 at step: 4879 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091725528145305 at step: 4880 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091687195055709 at step: 4881 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091648879279226 at step: 4882 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091610580804665 at step: 4883 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091572299620843 at step: 4884 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091534035716566 at step: 4885 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091495789080692 at step: 4886 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091457559702043 at step: 4887 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091419347569476 at step: 4888 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409138115267185 at step: 4889 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409134297499803 at step: 4890 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091304814536898 at step: 4891 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091266671277345 at step: 4892 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091228545208263 at step: 4893 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091190436318555 at step: 4894 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091152344597142 at step: 4895 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091114270032934 at step: 4896 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091076212614884 at step: 4897 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091038172331916 at step: 4898 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4091000149172987 at step: 4899 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090962143127062 at step: 4900 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.40909241541831 at step: 4901 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409088618233009 at step: 4902 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090848227557005 at step: 4903 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090810289852855 at step: 4904 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090772369206637 at step: 4905 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090734465607366 at step: 4906 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090696579044066 at step: 4907 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409065870950577 at step: 4908 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090620856981517 at step: 4909 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090583021460354 at step: 4910 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090545202931346 at step: 4911 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090507401383559 at step: 4912 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090469616806067 at step: 4913 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090431849187959 at step: 4914 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090394098518326 at step: 4915 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090356364786278 at step: 4916 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090318647980915 at step: 4917 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090280948091372 at step: 4918 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409024326510677 at step: 4919 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.409020559901626 at step: 4920 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090167949808972 at step: 4921 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090130317474074 at step: 4922 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090092702000732 at step: 4923 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090055103378116 at step: 4924 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4090017521595413 at step: 4925 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089979956641816 at step: 4926 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089942408506522 at step: 4927 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089904877178743 at step: 4928 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089867362647697 at step: 4929 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089829864902612 at step: 4930 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089792383932724 at step: 4931 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089754919727278 at step: 4932 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089717472275527 at step: 4933 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089680041566737 at step: 4934 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408964262759017 at step: 4935 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089605230335123 at step: 4936 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089567849790865 at step: 4937 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089530485946706 at step: 4938 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089493138791949 at step: 4939 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408945580831591 at step: 4940 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408941849450791 at step: 4941 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089381197357285 at step: 4942 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089343916853372 at step: 4943 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089306652985518 at step: 4944 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089269405743092 at step: 4945 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089232175115456 at step: 4946 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408919496109198 at step: 4947 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408915776366205 at step: 4948 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408912058281507 at step: 4949 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089083418540427 at step: 4950 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089046270827539 at step: 4951 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4089009139665822 at step: 4952 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088972025044708 at step: 4953 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088934926953625 at step: 4954 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088897845382025 at step: 4955 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088860780319359 at step: 4956 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088823731755085 at step: 4957 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088786699678673 at step: 4958 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088749684079613 at step: 4959 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088712684947382 at step: 4960 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088675702271476 at step: 4961 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088638736041401 at step: 4962 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408860178624667 at step: 4963 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088564852876808 at step: 4964 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088527935921338 at step: 4965 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408849103536981 at step: 4966 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088454151211756 at step: 4967 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088417283436743 at step: 4968 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088380432034324 at step: 4969 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088343596994084 at step: 4970 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088306778305602 at step: 4971 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088269975958454 at step: 4972 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088233189942247 at step: 4973 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408819642024659 at step: 4974 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.40881596668611 at step: 4975 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088122929775388 at step: 4976 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088086208979091 at step: 4977 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088049504461853 at step: 4978 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4088012816213316 at step: 4979 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087976144223135 at step: 4980 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408793948848099 at step: 4981 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087902848976537 at step: 4982 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087866225699461 at step: 4983 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087829618639458 at step: 4984 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087793027786222 at step: 4985 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087756453129463 at step: 4986 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408771989465889 at step: 4987 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087683352364233 at step: 4988 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408764682623522 at step: 4989 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087610316261587 at step: 4990 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087573822433097 at step: 4991 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087537344739487 at step: 4992 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087500883170532 at step: 4993 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087464437716009 at step: 4994 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087428008365688 at step: 4995 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087391595109369 at step: 4996 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087355197936842 at step: 4997 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.408731881683792 at step: 4998 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
Loss: 1.4087282451802412 at step: 4999 y: [ 1.14614024 -1.38375444] y_pred: [1.         0.99999998]
